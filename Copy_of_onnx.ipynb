{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of onnx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOy2vSs4gYRtuPpUb9SXt3f",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starminalush/mlops_report/blob/main/Copy_of_onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Устанавливаем нужные зависимости"
      ],
      "metadata": {
        "id": "XIhzpUzi6O93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx transformers onnxruntime folium==0.2.1 optimum[onnxruntime]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Fnu0cUxT-B",
        "outputId": "240ed39e-7aae-4396-fc88-67dcd2323003"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 11.5 MB/s \n",
            "\u001b[?25hCollecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 41.0 MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 44.2 MB/s \n",
            "\u001b[?25hCollecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.5 MB/s \n",
            "\u001b[?25hCollecting optimum[onnxruntime]\n",
            "  Downloading optimum-1.1.0.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 723 kB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 70.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 49.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.10.0+cu111)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.7.1)\n",
            "Collecting datasets>=1.2.1\n",
            "  Downloading datasets-2.0.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (6.0.1)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 64.1 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 61.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 58.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (1.3.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.3.4)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.70.12.2)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 69.8 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 62.3 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 4.3 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 63.2 MB/s \n",
            "\u001b[?25hCollecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2018.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->optimum[onnxruntime]) (1.2.1)\n",
            "Building wheels for collected packages: folium, optimum\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=070838de9108697e4ddd3781163bafc1e107ca5029755be0ec6596615b48ef33\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "  Building wheel for optimum (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.1.0-py3-none-any.whl size=78083 sha256=edfb0e238a1a91d37154af9febee9957f7e5b776568e7530230334c83cc08bf6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/60/d9/f202f46e221d01ca399545e03c3cfa0a183bc6f04cf367770f\n",
            "Successfully built folium optimum\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, humanfriendly, huggingface-hub, fsspec, aiohttp, xxhash, transformers, responses, coloredlogs, optimum, onnxruntime, onnx, datasets, folium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 coloredlogs-15.0.1 datasets-2.0.0 folium-0.2.1 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 humanfriendly-10.0 multidict-6.0.2 onnx-1.11.0 onnxruntime-1.11.0 optimum-1.1.0 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 tokenizers-0.11.6 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фиксируем версии библиотек"
      ],
      "metadata": {
        "id": "d2LrH-YLj6jK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > req.txt"
      ],
      "metadata": {
        "id": "RJtoXVKbj43r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорты"
      ],
      "metadata": {
        "id": "yX3P6Agw6jsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers.onnx import export\n",
        "from pathlib import Path\n",
        "from typing import Mapping, OrderedDict\n",
        "from transformers.onnx import OnnxConfig\n",
        "from transformers import AutoConfig\n",
        "import onnxruntime as nxrun\n",
        "import onnx\n",
        "import numpy as np\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from torch.nn.utils import prune\n",
        "from optimum.onnxruntime import ORTQuantizer"
      ],
      "metadata": {
        "id": "UPvsKtuB6iyY"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем rubert как есть"
      ],
      "metadata": {
        "id": "kCV1_Y3hjr4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "y68sxMotjS-K"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict('Правительство выделит 16 миллиардов рублей на поддержку клещей')\n",
        "#вернулся нейтральный класс"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halOX7lokqyT",
        "outputId": "3a92fc7b-3589-44a2-f1fb-ac023a08043f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 128 ms, sys: 46 µs, total: 128 ms\n",
            "Wall time: 142 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переводим в ONNX\n",
        "1. Есть библиотека transforms, где все из коробки\n",
        "\n",
        "https://huggingface.co/docs/transformers/serialization - делаем все по лучшим гайдам"
      ],
      "metadata": {
        "id": "HhA84H-tlJCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBertOnnxConfig(OnnxConfig):\n",
        "    @property\n",
        "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
        "        return OrderedDict(\n",
        "            [\n",
        "                (\"input_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"attention_mask\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"token_type_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "dXO_0DXu3e3s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\")\n",
        "onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=\"sequence-classification\")\n",
        "print(onnx_config_for_seq_clf.outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFThnLqO3O6d",
        "outputId": "3935a88d-706f-48f2-af92-b932c1b2d120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('logits', {0: 'batch'})])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/onnx_transforms"
      ],
      "metadata": {
        "id": "S6uO6quNkUSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        model,\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert.onnx\"),\n",
        "        opset=11)"
      ],
      "metadata": {
        "id": "8hPCv74Ylcje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем запустить в ONNX и посмотреть время инференса"
      ],
      "metadata": {
        "id": "jMKViWTow1s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "CeVlwXC8xbpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим на входы и выходы импортированной модели"
      ],
      "metadata": {
        "id": "sjzK5meE7v41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = model_ONNX.get_inputs()\n",
        "for input_name in input_names:\n",
        "  print(input_name.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqHVLLmLx0Fo",
        "outputId": "bbc616e0-3363-4b0e-c30d-6227e57751e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids\n",
            "attention_mask\n",
            "token_type_ids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for on in model_ONNX.get_outputs():\n",
        "  print(on.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHAtAZgZ0Atk",
        "outputId": "d144d070-7f02-4921-b318-4c11e333fa9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_onnx(text):\n",
        "  inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='np')\n",
        "  result  = model_ONNX.run(None, dict(inputs))\n",
        "  predicted = result.index(max(result))\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "iAu2HFt6x9WM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict_onnx('Правительство выделит 16 миллиардов рублей на поддержку клещей')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76ecT6N0a9e",
        "outputId": "cc98b77e-58fd-4e76-e890-15fa623fd5e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 56.3 ms, sys: 0 ns, total: 56.3 ms\n",
            "Wall time: 58.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Квантизация \n",
        "\n",
        "Делаем тоже по лучшим гайдам https://github.com/huggingface/optimum\n",
        "\n",
        "Есть три вида квантизации - статическая, динамическая и Quantization-Aware-Training(QAT)"
      ],
      "metadata": {
        "id": "xDQnTXSifdnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Динамическая квантизация не требует ничего, поэтому она самая простая"
      ],
      "metadata": {
        "id": "dd3MXWSQf1bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/quantization"
      ],
      "metadata": {
        "id": "SIteomPhgK3j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"blanchefort/rubert-base-cased-sentiment\"\n",
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained(model_checkpoint, feature=\"sequence-classification\")\n",
        "\n",
        "# Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"output/quantization/rubert.onnx\",\n",
        "    onnx_quantized_model_output_path=\"output/quantization/rubert-dyn-quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ],
      "metadata": {
        "id": "D5h7RVrMfUnP",
        "outputId": "19350a1e-cb8c-42ca-dfda-8cf1ce237173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('output/quantization/rubert-dyn-quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем запустить динамечески квантизированную ONNX модель и посмотреть на время инференса"
      ],
      "metadata": {
        "id": "--7npahjgBwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"/content/output/quantization/rubert-dyn-quantized.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "DcPhqkvdgPZv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict_onnx('Правительство выделит 16 миллиардов рублей на поддержку клещей')"
      ],
      "metadata": {
        "id": "ab-IIy12gSnd",
        "outputId": "1dae7f8c-b07d-444e-92e8-76ef7384dffc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 31.3 ms, sys: 4.81 ms, total: 36.1 ms\n",
            "Wall time: 37.9 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прунинг модели - и снова лучшие мануалы интернета https://github.com/Huffon/nlp-various-tutorials/blob/master/pruning-bert.ipynb"
      ],
      "metadata": {
        "id": "TpTwYCLrvtsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.bert.encoder.layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsrTyZzM7sRw",
        "outputId": "92c55d93-cb58-42b2-ffd7-ae7bca436bd8"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (1): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (2): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (3): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (4): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (5): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (6): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (7): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (8): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (9): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (10): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (11): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запруним энкодер слои"
      ],
      "metadata": {
        "id": "QMxrxaTf9yCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (final_model.bert.encoder.layer[i].attention.self.key, 'weight'),\n",
        "        (final_model.bert.encoder.layer[i].attention.self.query, 'weight'),\n",
        "        (final_model.bert.encoder.layer[i].attention.self.value, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "aunSquBo4Qr9"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.key.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.key.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.query.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.query.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.value.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.value.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.key.weight == 0)\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.query.weight == 0)\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.value.weight == 0)\n",
        "\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.key.weight.nelement()\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.query.weight.nelement()\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.value.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brkL0Q0u72EK",
        "outputId": "67105be8-6c9c-411d-f87b-75e73a48354e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th key weight: 18.59%\n",
            "Sparsity in Layer 1-th query weightt: 18.67%\n",
            "Sparsity in Layer 1-th value weight: 26.79%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 18.77%\n",
            "Sparsity in Layer 2-th query weightt: 18.33%\n",
            "Sparsity in Layer 2-th value weight: 25.69%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 20.08%\n",
            "Sparsity in Layer 3-th query weightt: 19.58%\n",
            "Sparsity in Layer 3-th value weight: 23.53%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 18.77%\n",
            "Sparsity in Layer 4-th query weightt: 18.49%\n",
            "Sparsity in Layer 4-th value weight: 24.32%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 18.40%\n",
            "Sparsity in Layer 5-th query weightt: 18.36%\n",
            "Sparsity in Layer 5-th value weight: 23.00%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 18.32%\n",
            "Sparsity in Layer 6-th query weightt: 17.84%\n",
            "Sparsity in Layer 6-th value weight: 21.55%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 18.54%\n",
            "Sparsity in Layer 7-th query weightt: 18.06%\n",
            "Sparsity in Layer 7-th value weight: 22.07%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 18.60%\n",
            "Sparsity in Layer 8-th query weightt: 18.45%\n",
            "Sparsity in Layer 8-th value weight: 20.83%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 18.14%\n",
            "Sparsity in Layer 9-th query weightt: 18.04%\n",
            "Sparsity in Layer 9-th value weight: 22.10%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 18.57%\n",
            "Sparsity in Layer 10-th query weightt: 18.31%\n",
            "Sparsity in Layer 10-th value weight: 21.78%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 18.64%\n",
            "Sparsity in Layer 11-th query weightt: 18.38%\n",
            "Sparsity in Layer 11-th value weight: 22.63%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 18.62%\n",
            "Sparsity in Layer 12-th query weightt: 18.31%\n",
            "Sparsity in Layer 12-th value weight: 20.84%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предиктим на запруненной модели"
      ],
      "metadata": {
        "id": "0L0XqK9i9Wqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = final_model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ],
      "metadata": {
        "id": "5DX9s0-a9VW7"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict('Правительство выделит 16 миллиардов рублей на поддержку клещей')\n",
        "#вернулся нейтральный класс"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKkXd1Yc9jtA",
        "outputId": "ba5c6140-bff6-45be-ba66-96595dcd5b8e"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 120 ms, sys: 1.11 ms, total: 121 ms\n",
            "Wall time: 134 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/pruning_quantization"
      ],
      "metadata": {
        "id": "tmheSjAr9rt2"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(final_model, 'output/pruning_quantization/pruned_bert.pt')"
      ],
      "metadata": {
        "id": "S6-5H9Cq-k9m"
      },
      "execution_count": 48,
      "outputs": []
    }
  ]
}