{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of onnx.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPkTyuRZsXxM1T26Tm6sPm/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starminalush/mlops_report/blob/main/onnx.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Устанавливаем нужные зависимости"
      ],
      "metadata": {
        "id": "XIhzpUzi6O93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install onnx transformers onnxruntime folium==0.2.1 optimum[onnxruntime]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Fnu0cUxT-B",
        "outputId": "ed1e66e2-4ec2-46b4-8db4-ce6bde117404"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: optimum[onnxruntime] in /usr/local/lib/python3.7/dist-packages (1.1.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.10.0.2)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.5.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.49)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.7.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.10.0+cu111)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (15.0.1)\n",
            "Requirement already satisfied: datasets>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (2.0.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (3.0.0)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (6.0.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (3.8.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.70.12.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (2022.3.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.3.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (1.3.5)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.18.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (4.0.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (21.4.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (2.0.12)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (1.2.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.7/dist-packages (from coloredlogs->optimum[onnxruntime]) (10.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2.8.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->optimum[onnxruntime]) (1.2.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Фиксируем версии библиотек"
      ],
      "metadata": {
        "id": "d2LrH-YLj6jK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip freeze > req.txt"
      ],
      "metadata": {
        "id": "RJtoXVKbj43r"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Импорты"
      ],
      "metadata": {
        "id": "yX3P6Agw6jsm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers.onnx import export\n",
        "from pathlib import Path\n",
        "from typing import Mapping, OrderedDict\n",
        "from transformers.onnx import OnnxConfig\n",
        "from transformers import AutoConfig\n",
        "import onnxruntime as nxrun\n",
        "import onnx\n",
        "import numpy as np\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from torch.nn.utils import prune\n",
        "from optimum.onnxruntime import ORTQuantizer"
      ],
      "metadata": {
        "id": "UPvsKtuB6iyY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запускаем rubert как есть"
      ],
      "metadata": {
        "id": "kCV1_Y3hjr4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "y68sxMotjS-K"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict('Правительство выделит 16 миллиардов рублей на поддержку клещей')\n",
        "#вернулся нейтральный класс"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halOX7lokqyT",
        "outputId": "b79f25c4-f54f-4541-857f-e569bc2f1df8"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 145 ms, sys: 17.7 ms, total: 162 ms\n",
            "Wall time: 166 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переводим в ONNX\n",
        "1. Есть библиотека transforms, где все из коробки\n",
        "\n",
        "https://huggingface.co/docs/transformers/serialization - делаем все по лучшим гайдам"
      ],
      "metadata": {
        "id": "HhA84H-tlJCl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistilBertOnnxConfig(OnnxConfig):\n",
        "    @property\n",
        "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
        "        return OrderedDict(\n",
        "            [\n",
        "                (\"input_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"attention_mask\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"token_type_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "            ]\n",
        "        )"
      ],
      "metadata": {
        "id": "dXO_0DXu3e3s"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\")\n",
        "onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=\"sequence-classification\")\n",
        "print(onnx_config_for_seq_clf.outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kFThnLqO3O6d",
        "outputId": "a92378e9-e907-4b26-bc43-16dd50a3b5f2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('logits', {0: 'batch'})])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/onnx_transforms"
      ],
      "metadata": {
        "id": "S6uO6quNkUSn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        model,\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert.onnx\"),\n",
        "        opset=11)"
      ],
      "metadata": {
        "id": "8hPCv74Ylcje"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем запустить в ONNX и посмотреть время инференса"
      ],
      "metadata": {
        "id": "jMKViWTow1s_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "CeVlwXC8xbpj"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Смотрим на входы и выходы импортированной модели"
      ],
      "metadata": {
        "id": "sjzK5meE7v41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_names = model_ONNX.get_inputs()\n",
        "for input_name in input_names:\n",
        "  print(input_name.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqHVLLmLx0Fo",
        "outputId": "8763ff81-36ef-4edc-931f-a80b03e34ea3"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_ids\n",
            "attention_mask\n",
            "token_type_ids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for on in model_ONNX.get_outputs():\n",
        "  print(on.name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHAtAZgZ0Atk",
        "outputId": "caaa47c0-aaab-4fd6-99bf-f5757f36bb98"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "logits\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_onnx(text):\n",
        "  inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='np')\n",
        "  result  = model_ONNX.run(None, dict(inputs))\n",
        "  predicted = result.index(max(result))\n",
        "  return predicted"
      ],
      "metadata": {
        "id": "iAu2HFt6x9WM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict_onnx('Правительство выделит 16 миллиардов рублей на поддержку клещей')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76ecT6N0a9e",
        "outputId": "57c3084e-b04d-42c6-8519-0e827a29e145"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 62 ms, sys: 2.02 ms, total: 64 ms\n",
            "Wall time: 67.9 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Квантизация \n",
        "\n",
        "Делаем тоже по лучшим гайдам https://github.com/huggingface/optimum\n",
        "\n",
        "Есть три вида квантизации - статическая, динамическая и Quantization-Aware-Training(QAT)"
      ],
      "metadata": {
        "id": "xDQnTXSifdnm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Динамическая квантизация не требует ничего, поэтому она самая простая"
      ],
      "metadata": {
        "id": "dd3MXWSQf1bF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/quantization"
      ],
      "metadata": {
        "id": "SIteomPhgK3j"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = \"blanchefort/rubert-base-cased-sentiment\"\n",
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained(model_checkpoint, feature=\"sequence-classification\")\n",
        "\n",
        "# Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"output/quantization/rubert.onnx\",\n",
        "    onnx_quantized_model_output_path=\"output/quantization/rubert-dyn-quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ],
      "metadata": {
        "id": "D5h7RVrMfUnP",
        "outputId": "271d32aa-6a12-4c87-cc2f-6b1452b4dbe5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('output/quantization/rubert-dyn-quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем запустить динамечески квантизированную ONNX модель и посмотреть на время инференса"
      ],
      "metadata": {
        "id": "--7npahjgBwa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"/content/output/quantization/rubert-dyn-quantized.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "DcPhqkvdgPZv"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict_onnx('Правительство выделит 16 миллиардов рублей на поддержку клещей')"
      ],
      "metadata": {
        "id": "ab-IIy12gSnd",
        "outputId": "acc21ac4-a8fb-4d49-cd38-4ace7c4f7486",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 41.1 ms, sys: 2.32 ms, total: 43.4 ms\n",
            "Wall time: 48 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Прунинг модели - и снова лучшие мануалы интернета https://github.com/Huffon/nlp-various-tutorials/blob/master/pruning-bert.ipynb\n",
        "\n",
        "\n",
        "https://aclanthology.org/2020.repl4nlp-1.18.pdf"
      ],
      "metadata": {
        "id": "TpTwYCLrvtsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.bert.encoder.layer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsrTyZzM7sRw",
        "outputId": "36c7f5ac-e939-4a30-a549-e583c3e57d1a"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ModuleList(\n",
              "  (0): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (1): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (2): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (3): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (4): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (5): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (6): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (7): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (8): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (9): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (10): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (11): BertLayer(\n",
              "    (attention): BertAttention(\n",
              "      (self): BertSelfAttention(\n",
              "        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (output): BertSelfOutput(\n",
              "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (intermediate): BertIntermediate(\n",
              "      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "      (intermediate_act_fn): GELUActivation()\n",
              "    )\n",
              "    (output): BertOutput(\n",
              "      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запруним энкодер слои"
      ],
      "metadata": {
        "id": "QMxrxaTf9yCy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_model = model\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (final_model.bert.encoder.layer[i].attention.self.key, 'weight'),\n",
        "        (final_model.bert.encoder.layer[i].attention.self.query, 'weight'),\n",
        "        (final_model.bert.encoder.layer[i].attention.self.value, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ],
      "metadata": {
        "id": "aunSquBo4Qr9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.key.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.key.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.query.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.query.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(final_model.bert.encoder.layer[i].attention.self.value.weight == 0))\n",
        "            / float(final_model.bert.encoder.layer[i].attention.self.value.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.key.weight == 0)\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.query.weight == 0)\n",
        "    numerator += torch.sum(final_model.bert.encoder.layer[i].attention.self.value.weight == 0)\n",
        "\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.key.weight.nelement()\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.query.weight.nelement()\n",
        "    denominator += final_model.bert.encoder.layer[i].attention.self.value.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brkL0Q0u72EK",
        "outputId": "6ec59bf8-190e-4995-d0d1-a8da0c6ce2a3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th key weight: 18.59%\n",
            "Sparsity in Layer 1-th query weightt: 18.67%\n",
            "Sparsity in Layer 1-th value weight: 26.79%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 18.77%\n",
            "Sparsity in Layer 2-th query weightt: 18.33%\n",
            "Sparsity in Layer 2-th value weight: 25.69%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 20.08%\n",
            "Sparsity in Layer 3-th query weightt: 19.58%\n",
            "Sparsity in Layer 3-th value weight: 23.53%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 18.77%\n",
            "Sparsity in Layer 4-th query weightt: 18.49%\n",
            "Sparsity in Layer 4-th value weight: 24.32%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 18.40%\n",
            "Sparsity in Layer 5-th query weightt: 18.36%\n",
            "Sparsity in Layer 5-th value weight: 23.00%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 18.32%\n",
            "Sparsity in Layer 6-th query weightt: 17.84%\n",
            "Sparsity in Layer 6-th value weight: 21.55%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 18.54%\n",
            "Sparsity in Layer 7-th query weightt: 18.06%\n",
            "Sparsity in Layer 7-th value weight: 22.07%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 18.60%\n",
            "Sparsity in Layer 8-th query weightt: 18.45%\n",
            "Sparsity in Layer 8-th value weight: 20.83%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 18.14%\n",
            "Sparsity in Layer 9-th query weightt: 18.04%\n",
            "Sparsity in Layer 9-th value weight: 22.10%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 18.57%\n",
            "Sparsity in Layer 10-th query weightt: 18.31%\n",
            "Sparsity in Layer 10-th value weight: 21.78%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 18.64%\n",
            "Sparsity in Layer 11-th query weightt: 18.38%\n",
            "Sparsity in Layer 11-th value weight: 22.63%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 18.62%\n",
            "Sparsity in Layer 12-th query weightt: 18.31%\n",
            "Sparsity in Layer 12-th value weight: 20.84%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Предиктим на запруненной модели"
      ],
      "metadata": {
        "id": "0L0XqK9i9Wqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = final_model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ],
      "metadata": {
        "id": "5DX9s0-a9VW7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict('Правительство выделит 16 миллиардов рублей на поддержку клещей')\n",
        "#вернулся нейтральный класс"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKkXd1Yc9jtA",
        "outputId": "8f9034f7-f33a-4020-c0b3-ec4d7c70018a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 128 ms, sys: 3.36 ms, total: 131 ms\n",
            "Wall time: 132 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p output/pruning"
      ],
      "metadata": {
        "id": "tmheSjAr9rt2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(final_model, 'output/pruning/pruned_bert.pt')"
      ],
      "metadata": {
        "id": "S6-5H9Cq-k9m"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Берем и конвертируем запруненную модель"
      ],
      "metadata": {
        "id": "t4jtfIKEBInu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        final_model,\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert_prunned.onnx\"),\n",
        "        opset=11)"
      ],
      "metadata": {
        "id": "YUVHDtkGAzec"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пробуем предиктить"
      ],
      "metadata": {
        "id": "Isvv_NjQBMHr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert_prunned.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "6VgCuDRsBNvE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "predict_onnx('Правительство выделит 16 миллиардов рублей на поддержку клещей')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_jiT4XaBXhc",
        "outputId": "fe8aaa5a-04af-4d11-f5dc-9eced1b85332"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 65.4 ms, sys: 448 µs, total: 65.8 ms\n",
            "Wall time: 67.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вес запруненной модели не поменялся, но хотя бы стало чуть быстрее на инференсе pt модели"
      ],
      "metadata": {
        "id": "YH5XNQuHEZbW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'original.pt')\n",
        "!du -shc original.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHnqiS2vEEAe",
        "outputId": "1a23a3bd-0afd-4b3e-d906-15fce13964df"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "922M\toriginal.pt\n",
            "922M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc /content/output/pruning/pruned_bert.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGv6PeoOCThp",
        "outputId": "1a8c2429-acb5-49ae-950a-c8ef728de1f5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "922M\t/content/output/pruning/pruned_bert.pt\n",
            "922M\ttotal\n"
          ]
        }
      ]
    }
  ]
}