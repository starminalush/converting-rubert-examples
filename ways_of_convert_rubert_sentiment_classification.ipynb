{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starminalush/mlops_report/blob/main/ways_of_convert_rubert_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Введение"
      ],
      "metadata": {
        "id": "NCqsfpgGKl0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот ноутбук для бекендеров, которым дали модельку и сказали деплоить так, чтобы она быстро работала. И больше ничего не дали, кроме модельки\n",
        "\t\n",
        "  (・_・ヾ"
      ],
      "metadata": {
        "id": "swO2xuTUxKuj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhzpUzi6O93"
      },
      "source": [
        "Устанавливаем нужные зависимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "98Fnu0cUxT-B",
        "outputId": "4c7c758c-17f1-40bf-cec7-92b2c76db445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 12.3 MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 36.3 MB/s \n",
            "\u001b[?25hCollecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 8.0 MB/s \n",
            "\u001b[?25hCollecting optimum[onnxruntime]\n",
            "  Downloading optimum-1.1.0.tar.gz (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx) (4.1.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx) (1.21.5)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx) (1.15.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 40.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 7.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.3)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 55.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.8)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime) (2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.7.1)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]) (1.10.0+cu111)\n",
            "Collecting datasets>=1.2.1\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.70.12.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (1.3.5)\n",
            "Collecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 53.3 MB/s \n",
            "\u001b[?25hCollecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 54.2 MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 40.4 MB/s \n",
            "\u001b[?25hCollecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (6.0.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]) (0.3.4)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 40.8 MB/s \n",
            "\u001b[?25hCollecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 58.5 MB/s \n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 51.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (21.4.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]) (2.0.12)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.6 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]) (2018.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->optimum[onnxruntime]) (1.2.1)\n",
            "Building wheels for collected packages: folium, optimum\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=814a29c6c1d8d8c5f83b99feef506982522ae084a7047d386482b9b8ee3a93d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "  Building wheel for optimum (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.1.0-py3-none-any.whl size=78083 sha256=0e93a5d0a84f586f4c8b1a4e08d19ea98206ab3652608f9c00d4e8e40acd4eab\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/60/d9/f202f46e221d01ca399545e03c3cfa0a183bc6f04cf367770f\n",
            "Successfully built folium optimum\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, humanfriendly, huggingface-hub, fsspec, aiohttp, xxhash, transformers, responses, coloredlogs, optimum, onnxruntime, datasets, folium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 coloredlogs-15.0.1 datasets-2.1.0 folium-0.2.1 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 humanfriendly-10.0 multidict-6.0.2 onnxruntime-1.11.0 optimum-1.1.0 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.49 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "urllib3"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install onnx transformers onnxruntime folium==0.2.1 optimum[onnxruntime]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LrH-YLj6jK"
      },
      "source": [
        "Фиксируем версии библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "RJtoXVKbj43r"
      },
      "outputs": [],
      "source": [
        "!pip freeze > req.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3P6Agw6jsm"
      },
      "source": [
        "Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "UPvsKtuB6iyY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers.onnx import export\n",
        "from pathlib import Path\n",
        "from typing import Mapping, OrderedDict\n",
        "from transformers.onnx import OnnxConfig\n",
        "from transformers import AutoConfig\n",
        "import onnxruntime as nxrun\n",
        "import onnx\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from torch.nn.utils import prune\n",
        "from optimum.onnxruntime import ORTQuantizer\n",
        "import tensorrt as trt\n",
        "from tensorrt import ICudaEngine, IExecutionContext\n",
        "from tensorrt.tensorrt import (\n",
        "    Builder,\n",
        "    IBuilderConfig,\n",
        "    IElementWiseLayer,\n",
        "    ILayer,\n",
        "    INetworkDefinition,\n",
        "    IOptimizationProfile,\n",
        "    IReduceLayer,\n",
        "    Logger,\n",
        "    OnnxParser,\n",
        "    Runtime,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качаем датасет, на котором будем проверять качество модели"
      ],
      "metadata": {
        "id": "PeVa2PBwZ-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/sismetanin/rureviews/raw/master/women-clothing-accessories.3-class.balanced.csv"
      ],
      "metadata": {
        "id": "bswJJzJwZ-ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Об нейросети"
      ],
      "metadata": {
        "id": "bN3PMwCwKu8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве подопытного будем использовать [rubert-base-cased-sentiment](https://huggingface.co/blanchefort/rubert-base-cased-sentiment) для классификации русских предложений. Данная нейросеть предсказывает 3 метки класса, в зависимости от тона предложения - позитивное, негативное или нейтральное"
      ],
      "metadata": {
        "id": "OnWsmqJ8JEID"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCV1_Y3hjr4C"
      },
      "source": [
        "Запускаем нейросеть как есть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "y68sxMotjS-K"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Как задолбали эти тупые правила: не есть кота, не бить посуду, не есть кота'"
      ],
      "metadata": {
        "id": "j3WKSWz8bsoJ"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим время инференса модели"
      ],
      "metadata": {
        "id": "tj7kkrS1R2KL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halOX7lokqyT",
        "outputId": "66c026bb-9376-426a-b683-f53038520adc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 131 ms, sys: 171 ms, total: 302 ms\n",
            "Wall time: 403 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "%%time\n",
        "predict(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим качество модели. Для проверки качества будем использовать один из датасетов, на котором обучалась модель, а именно [этот](https://github.com/sismetanin/rureviews)"
      ],
      "metadata": {
        "id": "jze-C8D-R6jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/women-clothing-accessories.3-class.balanced.csv', delimiter='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Blvw3zQqVSZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства немного изменим датасет - заменим метки класса на цифровые значения и выберем 1000 рандомных строк"
      ],
      "metadata": {
        "id": "ul8Y52nOVx_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df[:1000]\n",
        "mapping = {'negative': 2, 'positive': 1, 'neautral':0}\n",
        "df = df.replace({'sentiment': mapping})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3csvwJ45V6SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "QwNFigwRX451"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(df['review'])\n",
        "labels = list(df['sentiment'])"
      ],
      "metadata": {
        "id": "sziEW5X3X8qD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZg4zSOAYSAk",
        "outputId": "321cc3d7-52e1-43e5-b498-26116bfcc408"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7758420684835778, recall: 0.7625989008405051, f1score: 0.7586448839591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним оригинальную модель и посмотрим на ее вес"
      ],
      "metadata": {
        "id": "YCTWXOk829Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'output/original.pt')"
      ],
      "metadata": {
        "id": "mtpd-cj53F_V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/original.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jy4Ok3jw3OUR",
        "outputId": "a521cbbb-5122-4593-f29c-f2da34f8931a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "922M\toutput/original.pt\n",
            "922M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX"
      ],
      "metadata": {
        "id": "ITuXOm0CZ0Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формат Open Neural Network Exchange (ONNX) обеспечит общий способ представления данных, используемых в нейронных сетях. Большинство платформ имеют сегодня собственный специфический формат моделей, которые способны работать с моделями других платформ только при использовании специальных инструментов преобразования форматов.\n",
        "\n",
        "ONNX позволит осуществлять свободный обмен информацией, которой обладают модели, без процедуры преобразования. Модель, обученную на одной платформе, можно будет использовать и на другой платформе. Также можно будет модель, обученную на одном фреймворке, перенести на другой фреймворк.\n",
        "\n",
        "Перевести модель в ONNX можно несколькими способами:"
      ],
      "metadata": {
        "id": "p0aL7IAQaHje"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhA84H-tlJCl"
      },
      "source": [
        "1. Есть библиотека transforms, [где все почти из коробки](https://huggingface.co/docs/transformers/serialization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dXO_0DXu3e3s"
      },
      "outputs": [],
      "source": [
        "class DistilBertOnnxConfig(OnnxConfig):\n",
        "    @property\n",
        "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
        "        return OrderedDict(\n",
        "            [\n",
        "                (\"input_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"attention_mask\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"token_type_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kFThnLqO3O6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb392ab-8a41-4bcc-e1bd-b3ad3b2f9753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('logits', {0: 'batch'})])\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\")\n",
        "onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=\"sequence-classification\")\n",
        "print(onnx_config_for_seq_clf.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "S6uO6quNkUSn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/onnx_transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "8hPCv74Ylcje"
      },
      "outputs": [],
      "source": [
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        model,\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\"),\n",
        "        opset=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKViWTow1s_"
      },
      "source": [
        "Пробуем запустить в ONNX и посмотреть время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CeVlwXC8xbpj"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAu2HFt6x9WM"
      },
      "outputs": [],
      "source": [
        "def predict_onnx(text):\n",
        "  inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='np')\n",
        "  outputs  = model_ONNX.run(None, dict(inputs))[0][0]\n",
        "  result = np.where(outputs == np.amax(outputs))[0][0]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d76ecT6N0a9e",
        "outputId": "e9d08bd0-c028-4e26-af02-82f1a8b31b88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 89.7 ms, sys: 744 µs, total: 90.5 ms\n",
            "Wall time: 89.5 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "%%time\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "rdcziw6HeR6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t96PNPob8I0",
        "outputId": "e12f42a2-f769-4039-b5aa-27203fb653c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7758420684835778, recall: 0.7625989008405051, f1score: 0.7586448839591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "UrZPxeh_jCk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/onnx_transforms/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXjx9u88jFDz",
        "outputId": "c3fe0712-b911-4453-af6c-93e4aa607022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/onnx_transforms/rubert-base-cased-sentiment.onnx\n",
            "679M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала на порядок выше, метрики качества не изменились.Вес модели уменьшился на 300 мб"
      ],
      "metadata": {
        "id": "ncawUB5neW9b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TorchScript"
      ],
      "metadata": {
        "id": "6QZEJMl0exff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TorchScript — инструмент, который позволяет с помощью пары строк кода и нескольких щелчков мыши сделать из пайплайна на питоне отчуждаемое решение, которое можно встроить в систему на C++. А еще она будет на python работать быстрее из-за jit компиляции. В библиотеке transformers так же [есть почти из коробки](https://huggingface.co/docs/transformers/serialization#torchscript)"
      ],
      "metadata": {
        "id": "OOFNgikneVzn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Первым шагом нужно перезагрузить модель, добавив флаг torchscript=True"
      ],
      "metadata": {
        "id": "pygtakE0fvuJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_Gx7ViOnovm"
      },
      "outputs": [],
      "source": [
        "model_torchscript = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True, torchscript=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSjgRCg-nbhs",
        "outputId": "62665b75-7cbf-4fe3-b8c9-25335a9dfd6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  \n"
          ]
        }
      ],
      "source": [
        "inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "traced_model = torch.jit.trace(model_torchscript, [torch.tensor(x) for x in inputs.values()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rN15KXu3s_ZX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/torchscript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.jit.save(traced_model, \"output/torchscript/rubert-base-cased-sentiment_traced.pt\")"
      ],
      "metadata": {
        "id": "fWRFFZt1gMPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMMa85wtFU5"
      },
      "source": [
        "Пробуем предиктить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gkJz0sciq9K5"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_torchscript(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = traced_model(**inputs)[0]\n",
        "    predicted = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXfsa0HOtY-c",
        "outputId": "65f453ea-445e-47f0-9e90-c4b1eea449c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 110 ms, sys: 1.92 ms, total: 111 ms\n",
            "Wall time: 116 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "%%time\n",
        "predict_torchscript(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество модели"
      ],
      "metadata": {
        "id": "-wlPWFDfghd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_torchscript(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FW3k65H6gj7p",
        "outputId": "ccbbb22a-e0ce-4444-f59d-58c56a480fcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7758420684835778, recall: 0.7625989008405051, f1score: 0.7586448839591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "xBMIZs9_i907"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRTog6pvuSL1",
        "outputId": "277584a9-16d2-4273-f2e7-cea877547435"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/torchscript/rubert-base-cased-sentiment_traced.pt\n",
            "679M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/torchscript/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала немного выше, метрики качества не изменились.Вес модели изменился на 300мб примерно. Лучше, чем ничего"
      ],
      "metadata": {
        "id": "glxV-dR4jfW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Прунинг модели"
      ],
      "metadata": {
        "id": "7jV0b67TjnwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Pruning — обрезание избыточных частей сети для ускорения инференса без потери точности. Наглядно — откуда, сколько и как можно вырезать."
      ],
      "metadata": {
        "id": "KslsGyjYkFes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть два варианта, как прунить модель.\n",
        "\n",
        "1 вариант - библиотека [nn_pruning](https://github.com/huggingface/nn_pruning) от HuggingFace\n",
        "\n",
        "2 вариант - делать через torch.nn.utils.prune. В качестве примера есть данный [ноутбук](https://github.com/Huffon/nlp-various-tutorials/blob/master/pruning-bert.ipynb)"
      ],
      "metadata": {
        "id": "QQecIsnQx431"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpTwYCLrvtsi"
      },
      "source": [
        "[Ссылка](https://aclanthology.org/2020.repl4nlp-1.18.pdf) на почитать про прунинг модели BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMxrxaTf9yCy"
      },
      "source": [
        "Запруним encoder слои"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aunSquBo4Qr9"
      },
      "outputs": [],
      "source": [
        "pruned_model = model\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.key, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.query, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.value, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.2,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем, что получилось"
      ],
      "metadata": {
        "id": "AVBZ5em9y7y7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brkL0Q0u72EK",
        "outputId": "4d2a4cac-bcad-4b90-f75f-35b0992f3b52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th key weight: 18.59%\n",
            "Sparsity in Layer 1-th query weightt: 18.67%\n",
            "Sparsity in Layer 1-th value weight: 26.79%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 18.77%\n",
            "Sparsity in Layer 2-th query weightt: 18.33%\n",
            "Sparsity in Layer 2-th value weight: 25.69%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 20.08%\n",
            "Sparsity in Layer 3-th query weightt: 19.58%\n",
            "Sparsity in Layer 3-th value weight: 23.53%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 18.77%\n",
            "Sparsity in Layer 4-th query weightt: 18.49%\n",
            "Sparsity in Layer 4-th value weight: 24.32%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 18.40%\n",
            "Sparsity in Layer 5-th query weightt: 18.36%\n",
            "Sparsity in Layer 5-th value weight: 23.00%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 18.32%\n",
            "Sparsity in Layer 6-th query weightt: 17.84%\n",
            "Sparsity in Layer 6-th value weight: 21.55%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 18.54%\n",
            "Sparsity in Layer 7-th query weightt: 18.06%\n",
            "Sparsity in Layer 7-th value weight: 22.07%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 18.60%\n",
            "Sparsity in Layer 8-th query weightt: 18.45%\n",
            "Sparsity in Layer 8-th value weight: 20.83%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 18.14%\n",
            "Sparsity in Layer 9-th query weightt: 18.04%\n",
            "Sparsity in Layer 9-th value weight: 22.10%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 18.57%\n",
            "Sparsity in Layer 10-th query weightt: 18.31%\n",
            "Sparsity in Layer 10-th value weight: 21.78%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 18.64%\n",
            "Sparsity in Layer 11-th query weightt: 18.38%\n",
            "Sparsity in Layer 11-th value weight: 22.63%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 18.62%\n",
            "Sparsity in Layer 12-th query weightt: 18.31%\n",
            "Sparsity in Layer 12-th value weight: 20.84%\n",
            "\n",
            "Global sparsity: 20.00%\n"
          ]
        }
      ],
      "source": [
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0)\n",
        "\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L0XqK9i9Wqx"
      },
      "source": [
        "Предиктим на запруненной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DX9s0-a9VW7"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_pruned(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
        "    outputs = pruned_model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKkXd1Yc9jtA",
        "outputId": "c1040926-c3f8-4e64-adc4-b4578351965a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 148 ms, sys: 8 ms, total: 156 ms\n",
            "Wall time: 155 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "%%time\n",
        "predict_pruned(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmheSjAr9rt2"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6-5H9Cq-k9m"
      },
      "outputs": [],
      "source": [
        "torch.save(pruned_model, 'output/pruning/rubert-base-cased-sentiment_pruned.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем качество модели"
      ],
      "metadata": {
        "id": "jk8IWvdqzaiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_pruned(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tiTTVRFBzqOP",
        "outputId": "4889b8ce-d050-4070-f38f-2cb116826d77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7673895104392958, recall: 0.759069038827347, f1score: 0.7562227505683002\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "N1voUhql0oZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c90891b-9084-4c7e-8fa6-21b68e171f02",
        "id": "DzLIjxUd0oZ2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "922M\toutput/pruning/rubert-base-cased-sentiment_pruned.pt\n",
            "922M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/pruning/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод - вес модели не поменялся, качество упало чуть-чуть по сравнению с оригинальной моделью, но не критично. Модель стала работать быстрее, но ценой небольшой потери качества"
      ],
      "metadata": {
        "id": "5r9o1Bhk04UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Квантизация"
      ],
      "metadata": {
        "id": "ygi6u3xv3nK_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDQnTXSifdnm"
      },
      "source": [
        "Квантизация означает уменьшение численной точности весов модели. Один из популярных методов — k-means квантизация. Имея веса модели в матрице W с десятичными числами, веса кластеризуются с помощью k-means в N кластеров. Затем матрица W трансформируется в матрицу целых чисел от 1 до N, каждое из которых является указателем к центру кластера. Так можно сжать каждый элемент изначальной матрицы из 32-битного десятичного числа в log(N)-битные целые числа.\n",
        "\n",
        "Есть три вида квантизации - статическая, динамическая и Quantization-Aware-Training(QAT)\n",
        "\n",
        "\n",
        "Делаем тоже по лучшим гайдам https://github.com/huggingface/optimum\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3MXWSQf1bF"
      },
      "source": [
        "Динамическая квантизация не требует ничего, поэтому она самая простая"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIteomPhgK3j"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/quantization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5h7RVrMfUnP",
        "outputId": "42c6a6fc-3dfe-4c45-c99b-9751af7f3ddb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\", feature=\"sequence-classification\")\n",
        "\n",
        "# Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"output/quantization/rubert-base-cased-sentiment.onnx\",\n",
        "    onnx_quantized_model_output_path=\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--7npahjgBwa"
      },
      "source": [
        "Пробуем запустить динамечески квантизированную ONNX модель и посмотреть на время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcPhqkvdgPZv"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ab-IIy12gSnd",
        "outputId": "d5a5d011-cb81-4e28-a694-3542d0f92f17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 55.9 ms, sys: 856 µs, total: 56.7 ms\n",
            "Wall time: 57.8 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ],
      "source": [
        "%%time\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "EQ0Agafp43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "836a55a1-77ed-4e03-b280-249c9f516d78",
        "id": "xuQ36XHV43uB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7634891164434495, recall: 0.7515760349283417, f1score: 0.7473241689008997\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "EhFEQrOw43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/quantization/*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3fe0712-b911-4453-af6c-93e4aa607022",
        "id": "1BWVnSpI43uB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/onnx_transforms/rubert-base-cased-sentiment.onnx\n",
            "679M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с моделью в формате ONNX скорость инференса модели стала  выше, метрики качества немного просели.Вес модели не уменьшился"
      ],
      "metadata": {
        "id": "FJxqM9yu43uC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TensorRT"
      ],
      "metadata": {
        "id": "ny8G65VD4RcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "! Работает на тензорных ядрах, поэтому нужна тесла"
      ],
      "metadata": {
        "id": "2fbULjs24Wxt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Поэтому сначала поставим tensorrt, лучше из [архива](https://developer.nvidia.com/compute/machine-learning/tensorrt/secure/7.2.2/tars/TensorRT-7.2.2.3.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.0.tar.gz). Скачайте его и поместите на drive, затем выполните следующие команды"
      ],
      "metadata": {
        "id": "WncPAmYm2gZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lg0VQpfM5nRI",
        "outputId": "2b586d0c-3015-4a2f-c5f2-dd14953d585a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Apr 17 18:34:43 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8    30W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -V"
      ],
      "metadata": {
        "id": "LDrpPAd99psU",
        "outputId": "1ee819fb-9037-48d8-9d99-b170eda2f4f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!uname -m"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebNobKzmA1K0",
        "outputId": "6c1e9133-492a-40f6-9528-1f0d4330aa29"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x86_64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tar -xzvf /content/drive/MyDrive/TensorRT-7.2.2.3.Ubuntu-18.04.x86_64-gnu.cuda-11.1.cudnn8.0.tar.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qW0EZ39zyJ4",
        "outputId": "2dfb6ed1-5aca-4d8d-f6e7-bc89a15a7331"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorRT-7.2.2.3/\n",
            "TensorRT-7.2.2.3/bin\n",
            "TensorRT-7.2.2.3/lib\n",
            "TensorRT-7.2.2.3/targets/\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/bin/\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/bin/trtexec\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvcaffe_parser.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvcaffe_parser.so.7.2.2\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvcaffe_parser.so.7\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvcaffe_parser.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvparsers_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvparsers.so.7.2.2\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libprotobuf-lite.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libprotobuf.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvparsers.so.7\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvparsers.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer.so.7.2.2\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer.so.7\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer_plugin_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so.7.2.2\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so.7\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvinfer_plugin.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvonnxparser.so.7.2.2\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvonnxparser.so.7\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvonnxparser.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libnvonnxparser_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/libnvinfer.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/libnvparsers.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/libnvinfer_plugin.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/libnvonnxparser.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/stubs/libnvrtc_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin_compiler_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin_executor_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin_pattern_library_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin_pattern_runtime_static.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin.so\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin.so.1\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libmyelin.so.1.1.116\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/lib/libonnx_proto.a\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/include\n",
            "TensorRT-7.2.2.3/targets/x86_64-linux-gnu/samples\n",
            "TensorRT-7.2.2.3/samples/\n",
            "TensorRT-7.2.2.3/samples/sampleAlgorithmSelector/\n",
            "TensorRT-7.2.2.3/samples/sampleAlgorithmSelector/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleAlgorithmSelector/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleAlgorithmSelector/sampleAlgorithmSelector.cpp\n",
            "TensorRT-7.2.2.3/samples/Makefile\n",
            "TensorRT-7.2.2.3/samples/Makefile.config\n",
            "TensorRT-7.2.2.3/samples/sampleCharRNN/\n",
            "TensorRT-7.2.2.3/samples/sampleCharRNN/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleCharRNN/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleCharRNN/sampleCharRNN.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleDynamicReshape/\n",
            "TensorRT-7.2.2.3/samples/sampleDynamicReshape/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleDynamicReshape/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleDynamicReshape/sampleDynamicReshape.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleFasterRCNN/\n",
            "TensorRT-7.2.2.3/samples/sampleFasterRCNN/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleFasterRCNN/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleFasterRCNN/sampleFasterRCNN.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleGoogleNet/\n",
            "TensorRT-7.2.2.3/samples/sampleGoogleNet/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleGoogleNet/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleGoogleNet/sampleGoogleNet.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleINT8/\n",
            "TensorRT-7.2.2.3/samples/sampleINT8/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleINT8/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleINT8/sampleINT8.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleINT8API/\n",
            "TensorRT-7.2.2.3/samples/sampleINT8API/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleINT8API/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleINT8API/sampleINT8API.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/convert_weights.py\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/sampleMLP.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMLP/update_mlp.patch\n",
            "TensorRT-7.2.2.3/samples/sampleMNIST/\n",
            "TensorRT-7.2.2.3/samples/sampleMNIST/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleMNIST/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleMNIST/sampleMNIST.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMNISTAPI/\n",
            "TensorRT-7.2.2.3/samples/sampleMNISTAPI/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleMNISTAPI/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleMNISTAPI/sampleMNISTAPI.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/preprocess.py\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/sampleMovieLens.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLens/sampleMovieLensTraining.patch\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/chptToBin.py\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/component.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/cudaError.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/benchmarkWriter.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/benchmarkWriter.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/bleuScoreWriter.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/bleuScoreWriter.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/dataReader.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/dataWriter.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/dataWriter.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/limitedSamplesDataReader.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/limitedSamplesDataReader.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/sequenceProperties.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/textReader.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/textReader.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/textWriter.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/textWriter.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/vocabulary.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/data/vocabulary.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/deviceBuffer.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/get_newstest2015.sh\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/alignment.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/attention.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/beamSearchPolicy.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/beamSearchPolicy.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/componentWeights.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/componentWeights.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/contextNMT.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/contextNMT.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/debugUtil.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/debugUtil.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/decoder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/embedder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/encoder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/likelihood.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/likelihoodCombinationOperator.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/lstmDecoder.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/lstmDecoder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/lstmEncoder.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/lstmEncoder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/multiplicativeAlignment.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/multiplicativeAlignment.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/projection.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpAttention.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpAttention.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpEmbedder.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpEmbedder.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpProjection.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/slpProjection.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/softmaxLikelihood.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/model/softmaxLikelihood.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/pinnedHostBuffer.h\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/sampleNMT.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/trtUtil.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleNMT/trtUtil.h\n",
            "TensorRT-7.2.2.3/samples/sampleOnnxMNIST/\n",
            "TensorRT-7.2.2.3/samples/sampleOnnxMNIST/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleOnnxMNIST/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleOnnxMNIST/sampleOnnxMNIST.cpp\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/fcPlugin.h\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/fp16.h\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/Makefile\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/README.md\n",
            "TensorRT-7.2.2.3/samples/samplePlugin/samplePlugin.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleReformatFreeIO/\n",
            "TensorRT-7.2.2.3/samples/sampleReformatFreeIO/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleReformatFreeIO/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleReformatFreeIO/sampleReformatFreeIO.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/batchPrepare.py\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/PrepareINT8CalibrationBatches.sh\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/sampleSSD/sampleSSD.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/config.py\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/download_model.sh\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/fix_softmax.patch\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/frcnnUtils.h\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffFasterRCNN/sampleUffFasterRCNN.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleUffMNIST/\n",
            "TensorRT-7.2.2.3/samples/sampleUffMNIST/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleUffMNIST/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffMNIST/sampleUffMNIST.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/0001-Update-the-Mask_RCNN-model-from-NHWC-to-NCHW.patch\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/config.py\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/mrcnn_to_trt_single.py\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/converted/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/mrcnn_config.h\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffMaskRCNN/sampleUffMaskRCNN.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleUffPluginV2Ext/\n",
            "TensorRT-7.2.2.3/samples/sampleUffPluginV2Ext/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleUffPluginV2Ext/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffPluginV2Ext/sampleUffPluginV2Ext.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleUffSSD/\n",
            "TensorRT-7.2.2.3/samples/sampleUffSSD/config.py\n",
            "TensorRT-7.2.2.3/samples/sampleUffSSD/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleUffSSD/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleUffSSD/sampleUffSSD.cpp\n",
            "TensorRT-7.2.2.3/samples/trtexec/\n",
            "TensorRT-7.2.2.3/samples/trtexec/Makefile\n",
            "TensorRT-7.2.2.3/samples/trtexec/prn_utils.py\n",
            "TensorRT-7.2.2.3/samples/trtexec/profiler.py\n",
            "TensorRT-7.2.2.3/samples/trtexec/README.md\n",
            "TensorRT-7.2.2.3/samples/trtexec/tracer.py\n",
            "TensorRT-7.2.2.3/samples/trtexec/trtexec.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/Makefile\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/preprocess.py\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/README.md\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/sampleMovieLensMPS.cpp\n",
            "TensorRT-7.2.2.3/samples/sampleMovieLensMPS/sampleMovieLensTraining.patch\n",
            "TensorRT-7.2.2.3/samples/common/\n",
            "TensorRT-7.2.2.3/samples/common/BatchStream.h\n",
            "TensorRT-7.2.2.3/samples/common/EntropyCalibrator.h\n",
            "TensorRT-7.2.2.3/samples/common/ErrorRecorder.h\n",
            "TensorRT-7.2.2.3/samples/common/argsParser.h\n",
            "TensorRT-7.2.2.3/samples/common/buffers.h\n",
            "TensorRT-7.2.2.3/samples/common/common.h\n",
            "TensorRT-7.2.2.3/samples/common/dumpTFWts.py\n",
            "TensorRT-7.2.2.3/samples/common/getOptions.cpp\n",
            "TensorRT-7.2.2.3/samples/common/getOptions.h\n",
            "TensorRT-7.2.2.3/samples/common/half.h\n",
            "TensorRT-7.2.2.3/samples/common/logger.cpp\n",
            "TensorRT-7.2.2.3/samples/common/logger.h\n",
            "TensorRT-7.2.2.3/samples/common/logging.h\n",
            "TensorRT-7.2.2.3/samples/common/parserOnnxConfig.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleConfig.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleDevice.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleEngines.cpp\n",
            "TensorRT-7.2.2.3/samples/common/sampleEngines.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleInference.cpp\n",
            "TensorRT-7.2.2.3/samples/common/sampleInference.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleOptions.cpp\n",
            "TensorRT-7.2.2.3/samples/common/sampleOptions.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleReporting.cpp\n",
            "TensorRT-7.2.2.3/samples/common/sampleReporting.h\n",
            "TensorRT-7.2.2.3/samples/common/sampleUtils.h\n",
            "TensorRT-7.2.2.3/samples/python/\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/README.md\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/caffe_resnet50.py\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/onnx_resnet50.py\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/introductory_parser_samples/uff_resnet50.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/README.md\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/detect_objects.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/voc_evaluation.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/images/\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/images/image1.jpg\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/images/image2.jpg\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/images/image_details.txt\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/__init__.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/boxes.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/coco.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/engine.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/inference.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/mAP.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/model.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/paths.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_ssd/utils/voc.py\n",
            "TensorRT-7.2.2.3/samples/python/onnx_packnet/\n",
            "TensorRT-7.2.2.3/samples/python/onnx_packnet/README.md\n",
            "TensorRT-7.2.2.3/samples/python/onnx_packnet/convert_to_onnx.py\n",
            "TensorRT-7.2.2.3/samples/python/onnx_packnet/post_processing.py\n",
            "TensorRT-7.2.2.3/samples/python/onnx_packnet/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/README.md\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/coco_labels.txt\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/data_processing.py\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/onnx_to_tensorrt.py\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/yolov3_onnx/yolov3_to_onnx.py\n",
            "TensorRT-7.2.2.3/samples/python/int8_caffe_mnist/\n",
            "TensorRT-7.2.2.3/samples/python/int8_caffe_mnist/README.md\n",
            "TensorRT-7.2.2.3/samples/python/int8_caffe_mnist/calibrator.py\n",
            "TensorRT-7.2.2.3/samples/python/int8_caffe_mnist/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/int8_caffe_mnist/sample.py\n",
            "TensorRT-7.2.2.3/samples/python/end_to_end_tensorflow_mnist/\n",
            "TensorRT-7.2.2.3/samples/python/end_to_end_tensorflow_mnist/README.md\n",
            "TensorRT-7.2.2.3/samples/python/end_to_end_tensorflow_mnist/model.py\n",
            "TensorRT-7.2.2.3/samples/python/end_to_end_tensorflow_mnist/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/end_to_end_tensorflow_mnist/sample.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/CMakeLists.txt\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/README.md\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/__init__.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/lenet5.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/sample.py\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/plugin/\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/plugin/clipKernel.cu\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/plugin/clipKernel.h\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/plugin/customClipPlugin.cpp\n",
            "TensorRT-7.2.2.3/samples/python/uff_custom_plugin/plugin/customClipPlugin.h\n",
            "TensorRT-7.2.2.3/samples/python/common.py\n",
            "TensorRT-7.2.2.3/samples/python/network_api_pytorch_mnist/\n",
            "TensorRT-7.2.2.3/samples/python/network_api_pytorch_mnist/README.md\n",
            "TensorRT-7.2.2.3/samples/python/network_api_pytorch_mnist/model.py\n",
            "TensorRT-7.2.2.3/samples/python/network_api_pytorch_mnist/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/network_api_pytorch_mnist/sample.py\n",
            "TensorRT-7.2.2.3/samples/python/engine_refit_mnist/\n",
            "TensorRT-7.2.2.3/samples/python/engine_refit_mnist/README.md\n",
            "TensorRT-7.2.2.3/samples/python/engine_refit_mnist/model.py\n",
            "TensorRT-7.2.2.3/samples/python/engine_refit_mnist/requirements.txt\n",
            "TensorRT-7.2.2.3/samples/python/engine_refit_mnist/sample.py\n",
            "TensorRT-7.2.2.3/include/\n",
            "TensorRT-7.2.2.3/include/NvCaffeParser.h\n",
            "TensorRT-7.2.2.3/include/NvInfer.h\n",
            "TensorRT-7.2.2.3/include/NvInferPlugin.h\n",
            "TensorRT-7.2.2.3/include/NvInferPluginUtils.h\n",
            "TensorRT-7.2.2.3/include/NvInferRuntime.h\n",
            "TensorRT-7.2.2.3/include/NvInferVersion.h\n",
            "TensorRT-7.2.2.3/include/NvOnnxConfig.h\n",
            "TensorRT-7.2.2.3/include/NvUffParser.h\n",
            "TensorRT-7.2.2.3/include/NvUtils.h\n",
            "TensorRT-7.2.2.3/include/NvInferRuntimeCommon.h\n",
            "TensorRT-7.2.2.3/include/NvOnnxParser.h\n",
            "TensorRT-7.2.2.3/doc/\n",
            "TensorRT-7.2.2.3/doc/python/\n",
            "TensorRT-7.2.2.3/doc/python/infer/\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/DataType.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/DimensionType.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/Dims.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/HostMemory.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/Weights.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/FoundationalTypes/pyFoundationalTypes.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/Calibrator.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/EntropyCalibrator.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/EntropyCalibrator2.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/LegacyCalibrator.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/MinMaxCalibrator.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Int8/pyInt8.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Builder.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Engine.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/ErrorRecorder.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/ExecutionContext.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Logger.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/NetworkConfig.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/OptimizationProfile.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Profiler.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Refitter.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/Runtime.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Core/pyCore.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Graph/\n",
            "TensorRT-7.2.2.3/doc/python/infer/Graph/LayerBase.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Graph/Layers.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Graph/Network.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Graph/pyGraph.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Plugin/\n",
            "TensorRT-7.2.2.3/doc/python/infer/Plugin/IPluginCreator.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Plugin/IPluginFactory.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Plugin/IPluginRegistry.html\n",
            "TensorRT-7.2.2.3/doc/python/infer/Plugin/pyPlugin.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Onnx/\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Onnx/pyOnnx.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Caffe/\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Caffe/Plugins.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Caffe/pyCaffe.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Uff/\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Uff/Fields.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Uff/Plugins.html\n",
            "TensorRT-7.2.2.3/doc/python/parsers/Uff/pyUff.html\n",
            "TensorRT-7.2.2.3/doc/python/uff/\n",
            "TensorRT-7.2.2.3/doc/python/uff/Operators.html\n",
            "TensorRT-7.2.2.3/doc/python/uff/uff.html\n",
            "TensorRT-7.2.2.3/doc/python/_sources/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/coreConcepts.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/gettingStarted.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/index.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/migrationGuide.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/uff/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/uff/Operators.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/uff/uff.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/DataType.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/DimensionType.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/Dims.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/HostMemory.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/Weights.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/FoundationalTypes/pyFoundationalTypes.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/Calibrator.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/EntropyCalibrator.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/EntropyCalibrator2.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/LegacyCalibrator.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/MinMaxCalibrator.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Int8/pyInt8.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Graph/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Graph/LayerBase.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Graph/Layers.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Graph/Network.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Graph/pyGraph.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Engine.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/ExecutionContext.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Logger.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/NetworkConfig.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/OptimizationProfile.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Profiler.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Refitter.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Runtime.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/pyCore.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/ErrorRecorder.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Core/Builder.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Plugin/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Plugin/IPluginCreator.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Plugin/IPluginFactory.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Plugin/IPluginRegistry.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/infer/Plugin/pyPlugin.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Onnx/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Onnx/pyOnnx.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Uff/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Uff/Fields.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Uff/Plugins.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Uff/pyUff.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Caffe/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Caffe/Plugins.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/parsers/Caffe/pyCaffe.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/_sources/graphsurgeon/\n",
            "TensorRT-7.2.2.3/doc/python/_sources/graphsurgeon/graphsurgeon.rst.txt\n",
            "TensorRT-7.2.2.3/doc/python/graphsurgeon/\n",
            "TensorRT-7.2.2.3/doc/python/graphsurgeon/graphsurgeon.html\n",
            "TensorRT-7.2.2.3/doc/python/_static/\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-bold.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-bold.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-regular.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-regular.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-regular.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/RobotoSlab/roboto-slab-v7-regular.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/FontAwesome.otf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Light.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Light.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Regular.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Regular.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Thin.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Roboto-Slab-Thin.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/fontawesome-webfont.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/fontawesome-webfont.svg\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/fontawesome-webfont.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/fontawesome-webfont.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/fontawesome-webfont.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-bold-italic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-bold-italic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-normal-italic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-normal-italic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-normal.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/lato-normal.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bold.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bold.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bolditalic.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bolditalic.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bolditalic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-bolditalic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-italic.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-italic.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-italic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-italic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-regular.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-regular.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-regular.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/fonts/Lato/lato-regular.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/html5shiv.min.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/modernizr.min.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/theme.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/badge_only.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/js/html5shiv-printshiv.min.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/nvlogo_white.png\n",
            "TensorRT-7.2.2.3/doc/python/_static/pygments.css\n",
            "TensorRT-7.2.2.3/doc/python/_static/basic.css\n",
            "TensorRT-7.2.2.3/doc/python/_static/doctools.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/documentation_options.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/file.png\n",
            "TensorRT-7.2.2.3/doc/python/_static/jquery-3.4.1.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/jquery.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/language_data.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/minus.png\n",
            "TensorRT-7.2.2.3/doc/python/_static/plus.png\n",
            "TensorRT-7.2.2.3/doc/python/_static/searchtools.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/underscore-1.3.1.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/underscore.js\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/fontawesome-webfont.eot\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/fontawesome-webfont.svg\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/fontawesome-webfont.ttf\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/fontawesome-webfont.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/fontawesome-webfont.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-bold-italic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-bold-italic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-normal-italic.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-normal-italic.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-normal.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/lato-normal.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/Roboto-Slab-Bold.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/Roboto-Slab-Bold.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/Roboto-Slab-Regular.woff\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/fonts/Roboto-Slab-Regular.woff2\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/badge_only.css\n",
            "TensorRT-7.2.2.3/doc/python/_static/css/theme.css\n",
            "TensorRT-7.2.2.3/doc/python/coreConcepts.html\n",
            "TensorRT-7.2.2.3/doc/python/gettingStarted.html\n",
            "TensorRT-7.2.2.3/doc/python/index.html\n",
            "TensorRT-7.2.2.3/doc/python/genindex.html\n",
            "TensorRT-7.2.2.3/doc/python/search.html\n",
            "TensorRT-7.2.2.3/doc/python/.buildinfo\n",
            "TensorRT-7.2.2.3/doc/python/searchindex.js\n",
            "TensorRT-7.2.2.3/doc/python/objects.inv\n",
            "TensorRT-7.2.2.3/doc/python/migrationGuide.html\n",
            "TensorRT-7.2.2.3/doc/cpp/\n",
            "TensorRT-7.2.2.3/doc/cpp/annotated_dup.js\n",
            "TensorRT-7.2.2.3/doc/cpp/annotated.html\n",
            "TensorRT-7.2.2.3/doc/cpp/bc_s.png\n",
            "TensorRT-7.2.2.3/doc/cpp/bdwn.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classes.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_binary_proto_blob.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_binary_proto_blob.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_binary_proto_blob-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_blob_name_to_tensor.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_blob_name_to_tensor.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_blob_name_to_tensor-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_caffe_parser.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_caffe_parser.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_caffe_parser-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_v2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_v2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvcaffeparser1_1_1_i_plugin_factory_v2-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims2-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims2.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims3-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims3.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims4-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims4.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_c_h_w.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_c_h_w.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_c_h_w-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_c_h_w.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_exprs.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_exprs.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_exprs-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_h_w.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_h_w.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_h_w-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_h_w.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_n_c_h_w.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_n_c_h_w.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_n_c_h_w-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims_n_c_h_w.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_dims.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_activation_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_activation_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_activation_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_activation_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_context.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_context.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_context-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_i_o_info.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_i_o_info.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_i_o_info-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_selector.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_selector.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_selector-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_variant.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_variant.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_algorithm_variant-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder_config.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder_config.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder_config-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_builder-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_concatenation_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_concatenation_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_concatenation_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_concatenation_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_constant_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_constant_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_constant_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_constant_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_convolution_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_convolution_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_convolution_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_convolution_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_cuda_engine.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_cuda_engine.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_cuda_engine-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_deconvolution_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_deconvolution_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_deconvolution_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_deconvolution_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_dimension_expr.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_dimension_expr.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_dimension_expr-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_element_wise_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_element_wise_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_element_wise_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_element_wise_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_error_recorder.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_error_recorder.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_error_recorder-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_execution_context.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_execution_context.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_execution_context-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_expr_builder.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_expr_builder.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_expr_builder-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fill_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fill_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fill_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fill_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fully_connected_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fully_connected_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fully_connected_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_fully_connected_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gather_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gather_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gather_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gather_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gpu_allocator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gpu_allocator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_gpu_allocator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_host_memory.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_host_memory.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_host_memory-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_identity_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_identity_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_identity_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_identity_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_calibrator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_calibrator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_calibrator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_calibrator.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator2-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator2.png\n",
            "TensorRT-7.2.2.3/doc/cpp/closed.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_entropy_calibrator.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_legacy_calibrator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_legacy_calibrator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_legacy_calibrator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_legacy_calibrator.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_min_max_calibrator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_min_max_calibrator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_min_max_calibrator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_int8_min_max_calibrator.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_iterator_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_iterator_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_iterator_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_iterator_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_logger.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_logger.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_logger-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_boundary_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_boundary_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_boundary_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_boundary_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_output_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_output_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_output_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_loop_output_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_l_r_n_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_l_r_n_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_l_r_n_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_l_r_n_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_matrix_multiply_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_matrix_multiply_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_matrix_multiply_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_matrix_multiply_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_network_definition.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_network_definition.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_network_definition-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_optimization_profile.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_optimization_profile.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_optimization_profile-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_output_dimensions_formula.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_output_dimensions_formula.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_output_dimensions_formula-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_padding_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_padding_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_padding_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_padding_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_parametric_re_l_u_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_parametric_re_l_u_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_parametric_re_l_u_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_parametric_re_l_u_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_creator.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_creator.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_creator-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_factory.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_factory.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_factory-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_registry.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_registry.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_registry-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_dynamic_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_dynamic_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_dynamic_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_dynamic_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_i_o_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_i_o_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_i_o_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_i_o_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_plugin_v2.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_pooling_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_pooling_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_pooling_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_pooling_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_profiler.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_profiler.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_profiler-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_ragged_soft_max_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_ragged_soft_max_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_ragged_soft_max_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_ragged_soft_max_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_recurrence_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_recurrence_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_recurrence_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_recurrence_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_reduce_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_reduce_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_reduce_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_reduce_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_refitter.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_refitter.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_refitter-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_resize_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_resize_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_resize_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_resize_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_n_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_n_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_n_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_n_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_nv2_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_nv2_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_nv2_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_r_n_nv2_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_runtime.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_runtime.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_runtime-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_scale_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_scale_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_scale_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_scale_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_select_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_select_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_select_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_select_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shape_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shape_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shape_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shape_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shuffle_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shuffle_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shuffle_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_shuffle_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_slice_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_slice_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_slice_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_slice_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_soft_max_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_soft_max_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_soft_max_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_soft_max_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_tensor.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_tensor.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_tensor-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_top_k_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_top_k_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_top_k_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_top_k_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_trip_limit_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_trip_limit_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_trip_limit_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_trip_limit_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_unary_layer.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_unary_layer.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_unary_layer-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_i_unary_layer.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1plugin_1_1_i_nv_plugin.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1plugin_1_1_i_nv_plugin.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1plugin_1_1_i_nv_plugin-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1plugin_1_1_i_nv_plugin.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_field.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_field.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_field-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_registrar.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_registrar.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_plugin_registrar-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_weights.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_weights.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvinfer1_1_1_weights-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_onnx_config.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_onnx_config.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_onnx_config-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser_error.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser_error.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser_error-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvonnxparser_1_1_i_parser-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_field_map.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_field_map.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_field_map-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory_ext.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory_ext.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory_ext-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory_ext.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_plugin_factory.png\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_uff_parser.html\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_uff_parser.js\n",
            "TensorRT-7.2.2.3/doc/cpp/classnvuffparser_1_1_i_uff_parser-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/deprecated.html\n",
            "TensorRT-7.2.2.3/doc/cpp/dir_52d49dcd0c8b4549aeffb20cdf44c594.html\n",
            "TensorRT-7.2.2.3/doc/cpp/dir_a5a40681709ed751decc24cd7289c9c5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/dir_d44c64559bbebec7f509842c48db8b23.html\n",
            "TensorRT-7.2.2.3/doc/cpp/doc.png\n",
            "TensorRT-7.2.2.3/doc/cpp/doxygen.css\n",
            "TensorRT-7.2.2.3/doc/cpp/doxygen.png\n",
            "TensorRT-7.2.2.3/doc/cpp/dynsections.js\n",
            "TensorRT-7.2.2.3/doc/cpp/files_dup.js\n",
            "TensorRT-7.2.2.3/doc/cpp/files.html\n",
            "TensorRT-7.2.2.3/doc/cpp/folderclosed.png\n",
            "TensorRT-7.2.2.3/doc/cpp/folderopen.png\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_b.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_c.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_d.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_dup.js\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_e.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_enum.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_f.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_b.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_c.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_d.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_e.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_f.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_g.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_~.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_i.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func.js\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_l.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_m.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_n.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_o.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_p.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_r.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_s.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_t.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_u.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_func_w.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_g.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_~.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_i.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_k.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_l.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_m.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_n.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_o.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_p.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_r.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_s.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_t.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_type.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_u.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_vars.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_v.html\n",
            "TensorRT-7.2.2.3/doc/cpp/functions_w.html\n",
            "TensorRT-7.2.2.3/doc/cpp/globals_defs.html\n",
            "TensorRT-7.2.2.3/doc/cpp/globals_func.html\n",
            "TensorRT-7.2.2.3/doc/cpp/globals.html\n",
            "TensorRT-7.2.2.3/doc/cpp/globals_type.html\n",
            "TensorRT-7.2.2.3/doc/cpp/hierarchy.html\n",
            "TensorRT-7.2.2.3/doc/cpp/hierarchy.js\n",
            "TensorRT-7.2.2.3/doc/cpp/index.html\n",
            "TensorRT-7.2.2.3/doc/cpp/jquery.js\n",
            "TensorRT-7.2.2.3/doc/cpp/menudata.js\n",
            "TensorRT-7.2.2.3/doc/cpp/menu.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacemembers_enum.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacemembers_func.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacemembers.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacemembers_type.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvcaffeparser1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvcaffeparser1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvinfer1_1_1anonymous__namespace_02_nv_infer_8h_03.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvinfer1_1_1anonymous__namespace_02_nv_infer_runtime_8h_03.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvinfer1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvinfer1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvonnxparser_1_1anonymous__namespace_02_nv_onnx_parser_8h_03.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvonnxparser.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvonnxparser.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvuffparser.html\n",
            "TensorRT-7.2.2.3/doc/cpp/namespacenvuffparser.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespaces_dup.js\n",
            "TensorRT-7.2.2.3/doc/cpp/namespaces.html\n",
            "TensorRT-7.2.2.3/doc/cpp/nav_f.png\n",
            "TensorRT-7.2.2.3/doc/cpp/nav_g.png\n",
            "TensorRT-7.2.2.3/doc/cpp/nav_h.png\n",
            "TensorRT-7.2.2.3/doc/cpp/navtree.css\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreedata.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtreeindex6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/navtree.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_caffe_parser_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_caffe_parser_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_caffe_parser_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_utils_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_utils_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_plugin_utils_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_common_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_version_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_common_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_runtime_common_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_version_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_infer_version_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_config_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_config_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_config_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_parser_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_parser_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_onnx_parser_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_uff_parser_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_uff_parser_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_uff_parser_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_utils_8h.html\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_utils_8h.js\n",
            "TensorRT-7.2.2.3/doc/cpp/_nv_utils_8h_source.html\n",
            "TensorRT-7.2.2.3/doc/cpp/open.png\n",
            "TensorRT-7.2.2.3/doc/cpp/pages.html\n",
            "TensorRT-7.2.2.3/doc/cpp/resize.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_11.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_11.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_12.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_12.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_13.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_13.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_14.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_14.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_15.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_15.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_16.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_16.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_17.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_17.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/classes_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/namespaces_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/namespaces_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/files_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/files_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_a.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_a.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_b.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_b.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_c.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_c.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_d.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_d.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_e.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_e.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_f.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_f.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_10.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_10.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_11.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_11.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_12.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_12.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_13.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/functions_13.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/search_l.png\n",
            "TensorRT-7.2.2.3/doc/cpp/search/search_m.png\n",
            "TensorRT-7.2.2.3/doc/cpp/search/search_r.png\n",
            "TensorRT-7.2.2.3/doc/cpp/search/close.png\n",
            "TensorRT-7.2.2.3/doc/cpp/search/mag_sel.png\n",
            "TensorRT-7.2.2.3/doc/cpp/search/search.css\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_a.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_a.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_b.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_b.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_c.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_c.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_d.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_d.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_e.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_e.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_f.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_f.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_10.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/all_10.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/variables_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/typedefs_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_3.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_3.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_4.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_4.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_5.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_5.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_6.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_6.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_7.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_7.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_8.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_8.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_9.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_9.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_a.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_a.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_b.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_b.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_c.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_c.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_d.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_d.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_e.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_e.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_f.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_f.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_10.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enums_10.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enumvalues_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/enumvalues_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_1.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_1.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_2.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/defines_2.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/pages_0.html\n",
            "TensorRT-7.2.2.3/doc/cpp/search/pages_0.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/searchdata.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/search.js\n",
            "TensorRT-7.2.2.3/doc/cpp/search/nomatches.html\n",
            "TensorRT-7.2.2.3/doc/cpp/splitbar.png\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_dynamic_plugin_tensor_desc.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_dynamic_plugin_tensor_desc.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_dynamic_plugin_tensor_desc-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_permutation.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_permutation.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_permutation-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_detection_output_parameters.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_detection_output_parameters.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_detection_output_parameters-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_grid_anchor_parameters.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_grid_anchor_parameters.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_grid_anchor_parameters-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_n_m_s_parameters.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_n_m_s_parameters.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_n_m_s_parameters-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_prior_box_parameters.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_prior_box_parameters.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_prior_box_parameters-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_quadruple.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_quadruple.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_quadruple-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_region_parameters.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_region_parameters.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_region_parameters-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_r_p_r_o_i_params.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_r_p_r_o_i_params.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1_r_p_r_o_i_params-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1softmax_tree.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1softmax_tree.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1plugin_1_1softmax_tree-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_field_collection.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_field_collection.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_field_collection-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_tensor_desc.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_tensor_desc.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvinfer1_1_1_plugin_tensor_desc-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvuffparser_1_1_field_collection.html\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvuffparser_1_1_field_collection.js\n",
            "TensorRT-7.2.2.3/doc/cpp/structnvuffparser_1_1_field_collection-members.html\n",
            "TensorRT-7.2.2.3/doc/cpp/struct_plugin_version.html\n",
            "TensorRT-7.2.2.3/doc/cpp/sync_off.png\n",
            "TensorRT-7.2.2.3/doc/cpp/sync_on.png\n",
            "TensorRT-7.2.2.3/doc/cpp/tab_a.png\n",
            "TensorRT-7.2.2.3/doc/cpp/tab_b.png\n",
            "TensorRT-7.2.2.3/doc/cpp/tab_h.png\n",
            "TensorRT-7.2.2.3/doc/cpp/tabs.css\n",
            "TensorRT-7.2.2.3/doc/cpp/tab_s.png\n",
            "TensorRT-7.2.2.3/doc/Acknowledgements.txt\n",
            "TensorRT-7.2.2.3/doc/pdf/\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Best-Practices.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Developer-Guide.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Installation-Guide.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Release-Notes.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Sample-Support-Guide.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-SLA.pdf\n",
            "TensorRT-7.2.2.3/doc/pdf/TensorRT-Support-Matrix-Guide.pdf\n",
            "TensorRT-7.2.2.3/TensorRT-Release-Notes.pdf\n",
            "TensorRT-7.2.2.3/python/\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp27-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp34-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp35-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp36-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp37-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp38-none-linux_x86_64.whl\n",
            "TensorRT-7.2.2.3/uff/\n",
            "TensorRT-7.2.2.3/uff/uff-0.6.9-py2.py3-none-any.whl\n",
            "TensorRT-7.2.2.3/graphsurgeon/\n",
            "TensorRT-7.2.2.3/graphsurgeon/graphsurgeon-0.4.5-py2.py3-none-any.whl\n",
            "TensorRT-7.2.2.3/onnx_graphsurgeon/\n",
            "TensorRT-7.2.2.3/onnx_graphsurgeon/onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl\n",
            "TensorRT-7.2.2.3/data/\n",
            "TensorRT-7.2.2.3/data/char-rnn/\n",
            "TensorRT-7.2.2.3/data/char-rnn/model/\n",
            "TensorRT-7.2.2.3/data/char-rnn/model/checkpoint\n",
            "TensorRT-7.2.2.3/data/char-rnn/model/model-20080.data-00000-of-00001\n",
            "TensorRT-7.2.2.3/data/char-rnn/model/model-20080.index\n",
            "TensorRT-7.2.2.3/data/char-rnn/model/model-20080.meta\n",
            "TensorRT-7.2.2.3/data/char-rnn/char-rnn.wts\n",
            "TensorRT-7.2.2.3/data/mnist/\n",
            "TensorRT-7.2.2.3/data/mnist/mnist.onnx\n",
            "TensorRT-7.2.2.3/data/mnist/mnist.caffemodel\n",
            "TensorRT-7.2.2.3/data/mnist/mnist.prototxt\n",
            "TensorRT-7.2.2.3/data/mnist/mnist_lenet.caffemodel\n",
            "TensorRT-7.2.2.3/data/mnist/mnist_mean.binaryproto\n",
            "TensorRT-7.2.2.3/data/mnist/mnistapi.wts\n",
            "TensorRT-7.2.2.3/data/mnist/mnistgie.wts\n",
            "TensorRT-7.2.2.3/data/mnist/deploy.prototxt\n",
            "TensorRT-7.2.2.3/data/mnist/lenet5.uff\n",
            "TensorRT-7.2.2.3/data/mnist/lenet5.uff.txt\n",
            "TensorRT-7.2.2.3/data/mnist/lenet5_custom_pool.uff\n",
            "TensorRT-7.2.2.3/data/mnist/lenet5_custom_pool.uff.txt\n",
            "TensorRT-7.2.2.3/data/mnist/lenet5_mnist_frozen.pb\n",
            "TensorRT-7.2.2.3/data/mnist/download_pgms.py\n",
            "TensorRT-7.2.2.3/data/mnist/README.md\n",
            "TensorRT-7.2.2.3/data/mlp/\n",
            "TensorRT-7.2.2.3/data/mlp/sampleMLP.wts2\n",
            "TensorRT-7.2.2.3/data/movielens/\n",
            "TensorRT-7.2.2.3/data/movielens/movielens_ratings.txt\n",
            "TensorRT-7.2.2.3/data/movielens/sampleMovieLens.uff\n",
            "TensorRT-7.2.2.3/data/googlenet/\n",
            "TensorRT-7.2.2.3/data/googlenet/googlenet.caffemodel\n",
            "TensorRT-7.2.2.3/data/googlenet/googlenet.prototxt\n",
            "TensorRT-7.2.2.3/data/googlenet/README.md\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/000456.ppm\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/000542.ppm\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/001150.ppm\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/001763.ppm\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/004545.ppm\n",
            "TensorRT-7.2.2.3/data/faster-rcnn/faster_rcnn_test_iplugin.prototxt\n",
            "TensorRT-7.2.2.3/data/resnet50/\n",
            "TensorRT-7.2.2.3/data/resnet50/ResNet50_fp32.caffemodel\n",
            "TensorRT-7.2.2.3/data/resnet50/binoculars.jpeg\n",
            "TensorRT-7.2.2.3/data/resnet50/class_labels.txt\n",
            "TensorRT-7.2.2.3/data/resnet50/reflex_camera.jpeg\n",
            "TensorRT-7.2.2.3/data/resnet50/tabby_tiger_cat.jpg\n",
            "TensorRT-7.2.2.3/data/resnet50/ResNet50.onnx\n",
            "TensorRT-7.2.2.3/data/resnet50/README.md\n",
            "TensorRT-7.2.2.3/data/resnet50/ResNet50_N2.prototxt\n",
            "TensorRT-7.2.2.3/data/resnet50/airliner.ppm\n",
            "TensorRT-7.2.2.3/data/resnet50/resnet50-infer-5.uff\n",
            "TensorRT-7.2.2.3/data/ssd/\n",
            "TensorRT-7.2.2.3/data/ssd/bus.ppm\n",
            "TensorRT-7.2.2.3/data/ssd/dog.ppm\n",
            "TensorRT-7.2.2.3/data/ssd/ssd_coco_labels.txt\n",
            "TensorRT-7.2.2.3/data/ssd/batches/\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration46.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration47.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration47.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration48.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration48.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration49.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration49.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration5.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration5.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration6.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration6.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration7.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration7.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration8.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration8.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration9.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration9.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration18.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration18.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration19.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration19.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration2.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration2.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration20.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration20.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration21.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration21.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration22.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration22.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration23.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration23.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration24.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration24.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration25.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration25.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration26.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration26.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration27.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration0.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration0.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration1.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration1.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration10.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration10.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration11.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration11.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration12.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration12.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration13.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration13.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration14.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration14.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration15.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration15.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration16.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration16.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration17.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration17.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration27.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration28.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration28.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration29.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration29.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration3.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration3.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration30.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration30.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration31.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration31.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration32.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration32.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration33.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration33.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration34.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration34.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration35.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration35.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration36.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration36.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration37.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration37.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration38.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration38.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration39.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration39.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration4.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration4.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration40.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration40.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration41.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration41.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration42.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration42.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration43.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration43.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration44.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration44.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration45.batch\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration45.list\n",
            "TensorRT-7.2.2.3/data/ssd/batches/batch_calibration46.batch\n",
            "TensorRT-7.2.2.3/data/int8_api/\n",
            "TensorRT-7.2.2.3/data/int8_api/airliner.ppm\n",
            "TensorRT-7.2.2.3/data/int8_api/reference_labels.txt\n",
            "TensorRT-7.2.2.3/data/int8_api/resnet50_per_tensor_dynamic_range.txt\n",
            "TensorRT-7.2.2.3/data/int8_api/README.md\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls TensorRT-7.2.2.3\n",
        "!export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:TensorRT-7.2.2.3/lib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ePKZI5nw1P3P",
        "outputId": "c59ec541-cc93-46e5-cb94-6a3181f272d3"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bin   graphsurgeon  onnx_graphsurgeon  targets\n",
            "data  include\t    python\t       TensorRT-Release-Notes.pdf\n",
            "doc   lib\t    samples\t       uff\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp37-none-linux_x86_64.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgG4BEcC1dl1",
        "outputId": "1fc9bb32-69a5-4a23-a839-4dfe1b80489c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./TensorRT-7.2.2.3/python/tensorrt-7.2.2.3-cp37-none-linux_x86_64.whl\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-7.2.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install TensorRT-7.2.2.3/uff/uff-0.6.9-py2.py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03_Zs6cE1uPt",
        "outputId": "8d3fc06a-16b2-49dc-af73-83c4610a8011"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./TensorRT-7.2.2.3/uff/uff-0.6.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from uff==0.6.9) (1.21.5)\n",
            "Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.7/dist-packages (from uff==0.6.9) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.3.0->uff==0.6.9) (1.15.0)\n",
            "Installing collected packages: uff\n",
            "Successfully installed uff-0.6.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install TensorRT-7.2.2.3/graphsurgeon/graphsurgeon-0.4.5-py2.py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WSIB9612Bec",
        "outputId": "ebe62330-96cb-413b-e580-8e572387f49f"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./TensorRT-7.2.2.3/graphsurgeon/graphsurgeon-0.4.5-py2.py3-none-any.whl\n",
            "Installing collected packages: graphsurgeon\n",
            "Successfully installed graphsurgeon-0.4.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 -m pip install TensorRT-7.2.2.3/onnx_graphsurgeon/onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jTXk2LV2Mgu",
        "outputId": "5b5fcd2f-7af2-45ac-905d-2c7bac2ece73"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing ./TensorRT-7.2.2.3/onnx_graphsurgeon/onnx_graphsurgeon-0.2.6-py2.py3-none-any.whl\n",
            "Collecting onnx\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 12.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnx-graphsurgeon==0.2.6) (1.21.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-graphsurgeon==0.2.6) (4.1.1)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx->onnx-graphsurgeon==0.2.6) (3.17.3)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx->onnx-graphsurgeon==0.2.6) (1.15.0)\n",
            "Installing collected packages: onnx, onnx-graphsurgeon\n",
            "Successfully installed onnx-1.11.0 onnx-graphsurgeon-0.2.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pycuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y6F3xAkZ4Zwl",
        "outputId": "56b93692-e783-43b3-a2b6-902b9f3cfebf"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 13.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2022.1.3.tar.gz (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.0 MB/s \n",
            "\u001b[?25hCollecting mako\n",
            "  Downloading Mako-1.2.0-py3-none-any.whl (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting platformdirs>=2.2.0\n",
            "  Downloading platformdirs-2.5.1-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.21.5)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (4.1.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (4.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->mako->pycuda) (3.8.0)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=626634 sha256=1dd9b319b3fbdaccbfe94186da0fa4bab4bda60a23e904a1eb6b8d149cb423d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2022.1.3-py2.py3-none-any.whl size=64239 sha256=0c1fe0a8e4a1defe6ea055772f39a56e6371fe710665d664b2323867f36c4bc8\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/ea/cc/82049d3ddaad7909969ce140220641d70733db46ac09f4d8b4\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: platformdirs, pytools, mako, pycuda\n",
            "Successfully installed mako-1.2.0 platformdirs-2.5.1 pycuda-2021.1 pytools-2022.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "А теперь будем экспортировать модель в tensorrt"
      ],
      "metadata": {
        "id": "R-Azy9Cj3DVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy as np\n",
        "import tensorrt as trt"
      ],
      "metadata": {
        "id": "ubDNZs112XjF"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logger to capture errors, warnings, and other information during the build and inference phases\n",
        "TRT_LOGGER = trt.Logger()\n",
        "\n",
        "def build_engine(onnx_file_path):\n",
        "    # initialize TensorRT engine and parse ONNX model\n",
        "    builder = trt.Builder(TRT_LOGGER)\n",
        "    network = builder.create_network()\n",
        "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
        "    \n",
        "    # parse ONNX\n",
        "    with open(onnx_file_path, 'rb') as model:\n",
        "        print('Beginning ONNX file parsing')\n",
        "        parser.parse(model.read())\n",
        "    print('Completed parsing of ONNX file')\n",
        "    # allow TensorRT to use up to 1GB of GPU memory for tactic selection\n",
        "    builder.max_workspace_size = 1 << 30\n",
        "    # we have only one image in batch\n",
        "    builder.max_batch_size = 1\n",
        "    # use FP16 mode if possible\n",
        "    if builder.platform_has_fast_fp16:\n",
        "        builder.fp16_mode = True\n",
        "\n",
        "    # generate TensorRT engine optimized for the target platform\n",
        "    print('Building an engine...')\n",
        "    engine = builder.build_cuda_engine(network)\n",
        "    context = engine.create_execution_context()\n",
        "    print(\"Completed creating Engine\")\n",
        "\n",
        "    return engine, context\n",
        "\n",
        "def build_engine_onnx(model_file):\n",
        "  with trt.Builder(TRT_LOGGER) as builder, builder.create_network() as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
        "      builder.max_workspace_size = 1 << 30\n",
        "      # Load the Onnx model and parse it in order to populate the TensorRT network.\n",
        "      with open(model_file, 'rb') as model:\n",
        "          parser.parse(model.read())\n",
        "      return builder.build_cuda_engine(network) "
      ],
      "metadata": {
        "id": "KtQvUiAN4EIh"
      },
      "execution_count": 108,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "ways of convert rubert_sentiment_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1ce5RBtreotQMzJBUJz2mm9dv4BHlk1s0",
      "authorship_tag": "ABX9TyM6MR/Ilca9+4KlWVoytSe3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}