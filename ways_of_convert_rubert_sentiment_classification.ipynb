{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starminalush/mlops_report/blob/main/ways_of_convert_rubert_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Введение"
      ],
      "metadata": {
        "id": "NCqsfpgGKl0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот ноутбук для бекендеров, которым дали модельку и сказали деплоить так, чтобы она быстро работала. И больше ничего не дали, кроме модельки\n",
        "\t\n",
        "  (・_・ヾ"
      ],
      "metadata": {
        "id": "swO2xuTUxKuj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhzpUzi6O93"
      },
      "source": [
        "Устанавливаем нужные зависимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Fnu0cUxT-B",
        "outputId": "15a13cbb-898d-40c7-f3e6-68fa8f95b3af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnx in /usr/local/lib/python3.7/dist-packages (1.11.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.18.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.7/dist-packages (1.11.1)\n",
            "Requirement already satisfied: folium==0.2.1 in /usr/local/lib/python3.7/dist-packages (0.2.1)\n",
            "Requirement already satisfied: optimum[onnxruntime] in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch_pruning==0.3.0 (from versions: 0.1.0, 0.1.1, 0.1.2, 0.1.3, 0.1.4, 0.1.5, 0.2.0, 0.2.1, 0.2.4, 0.2.5, 0.2.6, 0.2.7)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for torch_pruning==0.3.0\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx transformers onnxruntime-gpu folium==0.2.1 optimum[onnxruntime]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LrH-YLj6jK"
      },
      "source": [
        "Фиксируем версии библиотек"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RJtoXVKbj43r"
      },
      "outputs": [],
      "source": [
        "!pip freeze > req.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3P6Agw6jsm"
      },
      "source": [
        "Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UPvsKtuB6iyY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import BertTokenizerFast\n",
        "from transformers.onnx import export\n",
        "from pathlib import Path\n",
        "from typing import Mapping, OrderedDict\n",
        "from transformers.onnx import OnnxConfig\n",
        "from transformers import AutoConfig\n",
        "import onnxruntime as nxrun\n",
        "import onnx\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from torch.nn.utils import prune\n",
        "from optimum.onnxruntime import ORTQuantizer\n",
        "from torch.onnx import TrainingMode\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качаем датасет, на котором будем проверять качество модели"
      ],
      "metadata": {
        "id": "PeVa2PBwZ-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/sismetanin/rureviews/raw/master/women-clothing-accessories.3-class.balanced.csv"
      ],
      "metadata": {
        "id": "bswJJzJwZ-ZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8883f5d9-34f9-4bb6-be8b-8ea7ddcd9d3f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-03 15:56:12--  https://github.com/sismetanin/rureviews/raw/master/women-clothing-accessories.3-class.balanced.csv\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/sismetanin/rureviews/master/women-clothing-accessories.3-class.balanced.csv [following]\n",
            "--2022-05-03 15:56:13--  https://raw.githubusercontent.com/sismetanin/rureviews/master/women-clothing-accessories.3-class.balanced.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 21781685 (21M) [text/plain]\n",
            "Saving to: ‘women-clothing-accessories.3-class.balanced.csv.3’\n",
            "\n",
            "women-clothing-acce 100%[===================>]  20.77M  69.2MB/s    in 0.3s    \n",
            "\n",
            "2022-05-03 15:56:13 (69.2 MB/s) - ‘women-clothing-accessories.3-class.balanced.csv.3’ saved [21781685/21781685]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Об нейросети"
      ],
      "metadata": {
        "id": "bN3PMwCwKu8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве подопытного будем использовать [rubert-base-cased-sentiment](https://huggingface.co/blanchefort/rubert-base-cased-sentiment) для классификации русских предложений. Данная нейросеть предсказывает 3 метки класса, в зависимости от тона предложения - позитивное, негативное или нейтральное"
      ],
      "metadata": {
        "id": "OnWsmqJ8JEID"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCV1_Y3hjr4C"
      },
      "source": [
        "Запускаем нейросеть как есть"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device  = torch.device('cuda') #будем все запускать на gpu"
      ],
      "metadata": {
        "id": "WAlMkNC-MUBc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y68sxMotjS-K"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True).to(device)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Как задолбали эти тупые правила: не есть кота, не бить посуду, не есть кота'"
      ],
      "metadata": {
        "id": "j3WKSWz8bsoJ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим время инференса модели"
      ],
      "metadata": {
        "id": "tj7kkrS1R2KL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halOX7lokqyT",
        "outputId": "cfaf480c-6b82-4062-9204-fb5213eac118"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 26.4 ms, sys: 1.92 ms, total: 28.3 ms\n",
            "Wall time: 30.5 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "%%time\n",
        "predict(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим качество модели. Для проверки качества будем использовать один из датасетов, на котором обучалась модель, а именно [этот](https://github.com/sismetanin/rureviews)"
      ],
      "metadata": {
        "id": "jze-C8D-R6jg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/women-clothing-accessories.3-class.balanced.csv', delimiter='\\t')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Blvw3zQqVSZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "b8743b6d-9352-4107-d2e3-e12eb9b2e859"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review sentiment\n",
              "0  качество плохое пошив ужасный (горловина напер...  negative\n",
              "1  Товар отдали другому человеку, я не получила п...  negative\n",
              "2  Ужасная синтетика! Тонкая, ничего общего с пре...  negative\n",
              "3  товар не пришел, продавец продлил защиту без м...  negative\n",
              "4      Кофточка голая синтетика, носить не возможно.  negative"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c599c34-e01d-4de1-9e19-63d008845680\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>качество плохое пошив ужасный (горловина напер...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Товар отдали другому человеку, я не получила п...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ужасная синтетика! Тонкая, ничего общего с пре...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>товар не пришел, продавец продлил защиту без м...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Кофточка голая синтетика, носить не возможно.</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c599c34-e01d-4de1-9e19-63d008845680')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c599c34-e01d-4de1-9e19-63d008845680 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c599c34-e01d-4de1-9e19-63d008845680');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства немного изменим датасет - заменим метки класса на цифровые значения и выберем 1000 рандомных строк"
      ],
      "metadata": {
        "id": "ul8Y52nOVx_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df[:1000]\n",
        "mapping = {'negative': 2, 'positive': 1, 'neautral':0}\n",
        "df = df.replace({'sentiment': mapping})\n",
        "df.head()"
      ],
      "metadata": {
        "id": "3csvwJ45V6SO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "32c6d0a9-4d3b-48bc-c70b-0bdb68eb6788"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Заказывала второй раз, порождала 4 месяца, но ...          1\n",
              "1  Отличный бюстгальтер, держится хорошо, пришёл ...          1\n",
              "2  Материал ужасный, нитки торчат,  короткая, еди...          2\n",
              "3                  заказ не пришел,но деньги вернули          2\n",
              "4  Продавец заявил-высокая талия,материал-поплин ...          2"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8606b2b9-4e58-46d3-8913-2b7d7c416a5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Заказывала второй раз, порождала 4 месяца, но ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Отличный бюстгальтер, держится хорошо, пришёл ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Материал ужасный, нитки торчат,  короткая, еди...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>заказ не пришел,но деньги вернули</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Продавец заявил-высокая талия,материал-поплин ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8606b2b9-4e58-46d3-8913-2b7d7c416a5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8606b2b9-4e58-46d3-8913-2b7d7c416a5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8606b2b9-4e58-46d3-8913-2b7d7c416a5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "QwNFigwRX451"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(df['review'])\n",
        "labels = list(df['sentiment'])"
      ],
      "metadata": {
        "id": "sziEW5X3X8qD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZg4zSOAYSAk",
        "outputId": "03bd6a08-d693-488a-adb9-1e67d9934c2f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7783219952095606, recall: 0.7634240759240759, f1score: 0.7558935727560435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним оригинальную модель и посмотрим на ее вес"
      ],
      "metadata": {
        "id": "YCTWXOk829Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output"
      ],
      "metadata": {
        "id": "uNKv-i2QcfGP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ac26bbd-3845-41aa-8e50-3a8780c287ce"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘output’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'output/original.pt')"
      ],
      "metadata": {
        "id": "mtpd-cj53F_V"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/original.pt"
      ],
      "metadata": {
        "id": "Jy4Ok3jw3OUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48a2ac9-808b-4a58-d43c-ef7883a310c2"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/original.pt\n",
            "679M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX"
      ],
      "metadata": {
        "id": "ITuXOm0CZ0Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формат Open Neural Network Exchange (ONNX) обеспечит общий способ представления данных, используемых в нейронных сетях. Большинство платформ имеют сегодня собственный специфический формат моделей, которые способны работать с моделями других платформ только при использовании специальных инструментов преобразования форматов.\n",
        "\n",
        "ONNX позволит осуществлять свободный обмен информацией, которой обладают модели, без процедуры преобразования. Модель, обученную на одной платформе, можно будет использовать и на другой платформе. Также можно будет модель, обученную на одном фреймворке, перенести на другой фреймворк.\n",
        "\n",
        "Перевести модель в ONNX можно несколькими способами:"
      ],
      "metadata": {
        "id": "p0aL7IAQaHje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Есть способ конвертации модели через torch.onnx"
      ],
      "metadata": {
        "id": "goPzxMVnadSP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "S6uO6quNkUSn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/onnx_transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.device"
      ],
      "metadata": {
        "id": "7rLcOElSsMgw",
        "outputId": "84dfceff-3698-4c77-cbd4-e3e0cb8c0dbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#делаем dummy input\n",
        "dummy_input0 = torch.randint(1, 224, (1,512)).to(device)\n",
        "dummy_input1 = torch.randint(0, 1, (1,512 )).to(device)\n",
        "dummy_input2 =  torch.randint(0, 1, (1,512 )).to(device)\n",
        "dummy_inputs = (dummy_input0,dummy_input1,dummy_input2)\n",
        "with torch.no_grad():\n",
        "  symbolic_names = {0:'batch_size', 1: 'max_seq_len'} \n",
        "  torch.onnx.export(model,               # модель, которую будем экспортировать\n",
        "                    dummy_inputs,                         # input модели\n",
        "                    \"output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\",   # путь сохранения модель\n",
        "                    export_params=True,        \n",
        "                    opset_version=11,          # версия ONNX, в который будем экспортировать модель\n",
        "                    do_constant_folding=True,\n",
        "                    input_names = [\"input_ids\",\"attention_mask\",\"token_type_ids\"],\n",
        "                    output_names = ['output'],\n",
        "                    dynamic_axes={'input_ids': symbolic_names,        #если у нас динамический размер input\n",
        "                                  'attention_mask' : symbolic_names,\n",
        "                                  'token_type_ids' : symbolic_names},\n",
        "                    training=TrainingMode.EVAL\n",
        "                    )"
      ],
      "metadata": {
        "id": "AsPlz8DGauZV"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKViWTow1s_"
      },
      "source": [
        "Пробуем запустить в ONNX и посмотреть время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "CeVlwXC8xbpj"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CUDAExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "iAu2HFt6x9WM"
      },
      "outputs": [],
      "source": [
        "def predict_onnx(text):\n",
        "  inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='np')\n",
        "  outputs  = model_ONNX.run(None, dict(inputs))[0][0]\n",
        "  result = np.where(outputs == np.amax(outputs))[0][0]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "d76ecT6N0a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e96e1cb-6494-4992-f466-31fb4b158939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 18 ms, sys: 0 ns, total: 18 ms\n",
            "Wall time: 18.2 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "%%time\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "rdcziw6HeR6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "_t96PNPob8I0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddb61c7-4428-4ac9-9c5c-6473b53d518c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7783219952095606, recall: 0.7634240759240759, f1score: 0.7558935727560435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "UrZPxeh_jCk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/onnx_transforms/*"
      ],
      "metadata": {
        "id": "BXjx9u88jFDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6c8a92f-0c99-4e86-d852-2a756f9b8b8e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/onnx_transforms/rubert-base-cased-sentiment.onnx\n",
            "679M\toutput/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\n",
            "1.4G\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала на порядок выше, метрики качества не изменились"
      ],
      "metadata": {
        "id": "ncawUB5neW9b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhA84H-tlJCl"
      },
      "source": [
        "2. Есть библиотека transforms для трансформеров, [где все почти из коробки](https://huggingface.co/docs/transformers/serialization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "dXO_0DXu3e3s"
      },
      "outputs": [],
      "source": [
        "class DistilBertOnnxConfig(OnnxConfig):\n",
        "    @property\n",
        "    def inputs(self) -> Mapping[str, Mapping[int, str]]:\n",
        "        return OrderedDict(\n",
        "            [\n",
        "                (\"input_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"attention_mask\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"token_type_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "kFThnLqO3O6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2438042-cffd-411f-c522-2cb1eed040e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('logits', {0: 'batch'})])\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\")\n",
        "onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=\"sequence-classification\")\n",
        "print(onnx_config_for_seq_clf.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "8hPCv74Ylcje"
      },
      "outputs": [],
      "source": [
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        model.to('cpu'),\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\"),\n",
        "        opset=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если проверить скорость инференса и качество, получим то же самое"
      ],
      "metadata": {
        "id": "WhrVYCm5w96r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "IvtrvbmqxCT7"
      },
      "outputs": [],
      "source": [
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b11f5e1-d196-4e84-ebf8-349f51c64444",
        "id": "REK315RPxCT8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 15.5 ms, sys: 2.75 ms, total: 18.2 ms\n",
            "Wall time: 18 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "%%time\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "691612c7-fc18-40f7-9058-1eed806a8b51",
        "id": "Y-7g0KH1xLXL"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7783219952095606, recall: 0.7634240759240759, f1score: 0.7558935727560435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TorchScript"
      ],
      "metadata": {
        "id": "6QZEJMl0exff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TorchScript — инструмент, который позволяет с помощью пары строк кода и нескольких щелчков мыши сделать из пайплайна на питоне отчуждаемое решение, которое можно встроить в систему на C++. А еще она будет на python работать быстрее из-за jit компиляции. В библиотеке transformers так же [есть почти из коробки](https://huggingface.co/docs/transformers/serialization#torchscript)"
      ],
      "metadata": {
        "id": "OOFNgikneVzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "z_Gx7ViOnovm"
      },
      "outputs": [],
      "source": [
        "tokenizer_torchscript = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment', torchscript = True)\n",
        "model_torchscript = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True, torchscript=True).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tSjgRCg-nbhs"
      },
      "outputs": [],
      "source": [
        "dummy_input0 = torch.randint(1, 224, (1,512)).to(device)\n",
        "dummy_input1 = torch.randint(0, 1, (1,512 )).to(device)\n",
        "dummy_input2 =  torch.randint(0, 1, (1,512 )).to(device)\n",
        "traced_model = torch.jit.trace(model_torchscript, [x.clone().detach() for x in dummy_inputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "rN15KXu3s_ZX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/torchscript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.jit.save(traced_model, \"output/torchscript/rubert-base-cased-sentiment_traced.pt\")"
      ],
      "metadata": {
        "id": "fWRFFZt1gMPP"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMMa85wtFU5"
      },
      "source": [
        "Пробуем загрузить и предиктить"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "gkJz0sciq9K5"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_torchscript(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = traced_model(**inputs)[0]\n",
        "    predicted = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "bXfsa0HOtY-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a1b647-15eb-48c8-a7cc-d761ad5266ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4 s, sys: 104 ms, total: 4.11 s\n",
            "Wall time: 4.6 s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "%%time\n",
        "predict_torchscript(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество модели"
      ],
      "metadata": {
        "id": "-wlPWFDfghd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_torchscript(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "FW3k65H6gj7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7ddce34-2fea-432c-e40c-f9a702c78bd6"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7783219952095606, recall: 0.7634240759240759, f1score: 0.7558935727560435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "xBMIZs9_i907"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "WRTog6pvuSL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "feebd6c7-8461-4e47-f319-83a02fe4bce3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/torchscript/rubert-base-cased-sentiment_traced.pt\n",
            "679M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/torchscript/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала немного выше, метрики качества не изменились. Лучше, чем ничего. А вообще надо а с++ запускать, чтобы увидеть адекватный результат"
      ],
      "metadata": {
        "id": "glxV-dR4jfW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Прунинг модели"
      ],
      "metadata": {
        "id": "7jV0b67TjnwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Pruning — обрезание избыточных частей сети для ускорения инференса без потери точности. Наглядно — откуда, сколько и как можно вырезать."
      ],
      "metadata": {
        "id": "KslsGyjYkFes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть очень много способов прунинга моделей, но здесь мы рассмотрим способ прунинга attention слоев"
      ],
      "metadata": {
        "id": "0PyJxe0RaJ4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть два варианта, как прунить модель.\n",
        "\n",
        "1 вариант - делать через torch.nn.utils.prune. В качестве примера есть данный [ноутбук](https://github.com/Huffon/nlp-various-tutorials/blob/master/pruning-bert.ipynb)\n",
        "\n",
        "2 вариант - библиотека [nn_pruning](https://github.com/huggingface/nn_pruning) от HuggingFace\n"
      ],
      "metadata": {
        "id": "QQecIsnQx431"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpTwYCLrvtsi"
      },
      "source": [
        "[Ссылка](https://aclanthology.org/2020.repl4nlp-1.18.pdf) на почитать про прунинг модели BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMxrxaTf9yCy"
      },
      "source": [
        "Запруним encoder слои"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "laqVNM52oYsS",
        "outputId": "ff26662a-7829-45f8-860c-985bc8d979b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "aunSquBo4Qr9"
      },
      "outputs": [],
      "source": [
        "pruned_model = model.to(device)\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.key, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.query, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.value, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.RandomUnstructured,\n",
        "    amount=0.9\n",
        ")\n",
        "for p in parameters_to_prune:\n",
        "  prune.remove(p[0], 'weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем, что получилось"
      ],
      "metadata": {
        "id": "AVBZ5em9y7y7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "brkL0Q0u72EK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb7dd319-c88f-4a0f-a911-f8c9196b1bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th key weight: 99.00%\n",
            "Sparsity in Layer 1-th query weightt: 99.02%\n",
            "Sparsity in Layer 1-th value weight: 99.02%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 99.00%\n",
            "Sparsity in Layer 2-th query weightt: 98.99%\n",
            "Sparsity in Layer 2-th value weight: 99.00%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 99.01%\n",
            "Sparsity in Layer 3-th query weightt: 99.00%\n",
            "Sparsity in Layer 3-th value weight: 99.00%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 99.02%\n",
            "Sparsity in Layer 4-th query weightt: 98.98%\n",
            "Sparsity in Layer 4-th value weight: 98.99%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 98.99%\n",
            "Sparsity in Layer 5-th query weightt: 98.99%\n",
            "Sparsity in Layer 5-th value weight: 99.01%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 99.02%\n",
            "Sparsity in Layer 6-th query weightt: 99.00%\n",
            "Sparsity in Layer 6-th value weight: 99.01%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 98.98%\n",
            "Sparsity in Layer 7-th query weightt: 99.00%\n",
            "Sparsity in Layer 7-th value weight: 99.01%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 99.00%\n",
            "Sparsity in Layer 8-th query weightt: 98.98%\n",
            "Sparsity in Layer 8-th value weight: 99.00%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 99.01%\n",
            "Sparsity in Layer 9-th query weightt: 98.99%\n",
            "Sparsity in Layer 9-th value weight: 99.01%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 98.99%\n",
            "Sparsity in Layer 10-th query weightt: 98.99%\n",
            "Sparsity in Layer 10-th value weight: 99.01%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 99.00%\n",
            "Sparsity in Layer 11-th query weightt: 99.02%\n",
            "Sparsity in Layer 11-th value weight: 99.03%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 99.01%\n",
            "Sparsity in Layer 12-th query weightt: 99.02%\n",
            "Sparsity in Layer 12-th value weight: 99.00%\n",
            "\n",
            "Global sparsity: 99.00%\n"
          ]
        }
      ],
      "source": [
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0)\n",
        "\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L0XqK9i9Wqx"
      },
      "source": [
        "Предиктим на запруненной модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "5DX9s0-a9VW7"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_pruned(text):\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = pruned_model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "oKkXd1Yc9jtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e676881-07f2-4fe7-a553-3f3c2403a698"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 25.8 ms, sys: 0 ns, total: 25.8 ms\n",
            "Wall time: 27.4 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "%%time\n",
        "predict_pruned(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "tmheSjAr9rt2"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "S6-5H9Cq-k9m"
      },
      "outputs": [],
      "source": [
        "torch.save(pruned_model, 'output/pruning/rubert-base-cased-sentiment_pruned.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем качество модели"
      ],
      "metadata": {
        "id": "jk8IWvdqzaiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_pruned(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "tiTTVRFBzqOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eee117d-feab-4f2f-d188-ca3af8abaa47"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.112, recall: 0.3333333333333333, f1score: 0.16766467065868262\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "N1voUhql0oZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "DzLIjxUd0oZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de332451-be1c-4620-f0b7-8672e25941e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/pruning/rubert-base-cased-sentiment_pruned.pt\n",
            "679M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/pruning/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод - вес модели не поменялся, качество упало чуть-чуть по сравнению с оригинальной моделью, но не критично. Модель стала работать быстрее, но ценой небольшой потери качества"
      ],
      "metadata": {
        "id": "5r9o1Bhk04UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Квантизация"
      ],
      "metadata": {
        "id": "ygi6u3xv3nK_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDQnTXSifdnm"
      },
      "source": [
        "Квантизация означает уменьшение численной точности весов модели. Один из популярных методов — k-means квантизация. Имея веса модели в матрице W с десятичными числами, веса кластеризуются с помощью k-means в N кластеров. Затем матрица W трансформируется в матрицу целых чисел от 1 до N, каждое из которых является указателем к центру кластера. Так можно сжать каждый элемент изначальной матрицы из 32-битного десятичного числа в log(N)-битные целые числа.\n",
        "\n",
        "Есть три вида квантизации - статическая, динамическая и Quantization-Aware-Training(QAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3MXWSQf1bF"
      },
      "source": [
        "Динамическая квантизация не требует ничего, поэтому она самая простая"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "SIteomPhgK3j"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно квантизировать модель через библиотеку onnxruntime "
      ],
      "metadata": {
        "id": "zP9ACDI5yVLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = 'output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx'\n",
        "model_quant = 'output/quantization/rubert-base-cased-sentiment.quant.onnx'\n",
        "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
      ],
      "metadata": {
        "id": "U3TcKmpmyaRv",
        "outputId": "c7b69c24-fe35-485c-e69e-8a904a961b76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore MatMul due to non constant B: /[MatMul_68]\n",
            "Ignore MatMul due to non constant B: /[MatMul_73]\n",
            "Ignore MatMul due to non constant B: /[MatMul_162]\n",
            "Ignore MatMul due to non constant B: /[MatMul_167]\n",
            "Ignore MatMul due to non constant B: /[MatMul_256]\n",
            "Ignore MatMul due to non constant B: /[MatMul_261]\n",
            "Ignore MatMul due to non constant B: /[MatMul_350]\n",
            "Ignore MatMul due to non constant B: /[MatMul_355]\n",
            "Ignore MatMul due to non constant B: /[MatMul_444]\n",
            "Ignore MatMul due to non constant B: /[MatMul_449]\n",
            "Ignore MatMul due to non constant B: /[MatMul_538]\n",
            "Ignore MatMul due to non constant B: /[MatMul_543]\n",
            "Ignore MatMul due to non constant B: /[MatMul_632]\n",
            "Ignore MatMul due to non constant B: /[MatMul_637]\n",
            "Ignore MatMul due to non constant B: /[MatMul_726]\n",
            "Ignore MatMul due to non constant B: /[MatMul_731]\n",
            "Ignore MatMul due to non constant B: /[MatMul_820]\n",
            "Ignore MatMul due to non constant B: /[MatMul_825]\n",
            "Ignore MatMul due to non constant B: /[MatMul_914]\n",
            "Ignore MatMul due to non constant B: /[MatMul_919]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1008]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1013]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1102]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--7npahjgBwa"
      },
      "source": [
        "Пробуем запустить динамечески квантизированную ONNX модель и посмотреть на время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "id": "DcPhqkvdgPZv"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CUDAExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 112,
      "metadata": {
        "id": "ab-IIy12gSnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bfae792-ca1a-4e60-c3f8-19586f8516c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 71.2 ms, sys: 884 µs, total: 72.1 ms\n",
            "Wall time: 75.7 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ],
      "source": [
        "%%time\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "EQ0Agafp43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "xuQ36XHV43uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d9f91a-dfab-4b54-9e34-8e76a9e58cd6"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7725823838727065, recall: 0.7604929792429793, f1score: 0.7525480092127617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно так же через библиотеку optimum от transformers"
      ],
      "metadata": {
        "id": "YLil08WNY9Z2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "D5h7RVrMfUnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16add971-8d62-4ef6-bac3-0bb1220f8ced"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ],
      "source": [
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\", feature=\"sequence-classification\")\n",
        "\n",
        "# Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"output/quantization/rubert-base-cased-sentiment.onnx\",\n",
        "    onnx_quantized_model_output_path=\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "EhFEQrOw43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/quantization/*"
      ],
      "metadata": {
        "id": "1BWVnSpI43uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f50971-7e7e-4acc-bbe5-35c265d00e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436M\toutput/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\n",
            "679M\toutput/quantization/rubert-base-cased-sentiment.onnx\n",
            "171M\toutput/quantization/rubert-base-cased-sentiment.quant.onnx\n",
            "1.3G\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с моделью в формате ONNX скорость инференса модели стала  выше, метрики качества немного просели.Вес модели не уменьшился"
      ],
      "metadata": {
        "id": "FJxqM9yu43uC"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of ways of convert rubert_sentiment_classification.ipynb",
      "provenance": [],
      "mount_file_id": "1ce5RBtreotQMzJBUJz2mm9dv4BHlk1s0",
      "authorship_tag": "ABX9TyNrxXovHcOEZN7wBq41gkbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}