{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/starminalush/mlops_report/blob/main/ways_of_convert_rubert_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Введение"
      ],
      "metadata": {
        "id": "NCqsfpgGKl0s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Этот ноутбук для бекендеров, которым дали модельку и сказали деплоить так, чтобы она быстро работала. И больше ничего не дали, кроме модельки\n",
        "\t\n",
        "  (・_・ヾ"
      ],
      "metadata": {
        "id": "swO2xuTUxKuj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIhzpUzi6O93"
      },
      "source": [
        "Устанавливаем нужные зависимости"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98Fnu0cUxT-B",
        "outputId": "dd054a6d-f4e7-420d-dd39-0458fabdca47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting onnx==1.11.0\n",
            "  Downloading onnx-1.11.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (12.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 12.8 MB 5.0 MB/s \n",
            "\u001b[?25hCollecting transformers==4.18.0\n",
            "  Downloading transformers-4.18.0-py3-none-any.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 38.2 MB/s \n",
            "\u001b[?25hCollecting onnxruntime-gpu==1.11.0\n",
            "  Downloading onnxruntime_gpu-1.11.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (108.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 108.9 MB 4.6 kB/s \n",
            "\u001b[?25hCollecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[K     |████████████████████████████████| 69 kB 5.4 MB/s \n",
            "\u001b[?25hCollecting optimum[onnxruntime]==1.1.1\n",
            "  Downloading optimum-1.1.1.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 2.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx==1.11.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.11.0) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.12.2 in /usr/local/lib/python3.7/dist-packages (from onnx==1.11.0) (3.17.3)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.5.1-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[K     |████████████████████████████████| 880 kB 40.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2.23.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 38.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.64.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (3.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (2019.12.20)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.18.0) (4.11.3)\n",
            "Collecting tokenizers!=0.11.3,<0.13,>=0.11.1\n",
            "  Downloading tokenizers-0.12.1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 35.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.7/dist-packages (from onnxruntime-gpu==1.11.0) (2.0)\n",
            "Requirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]==1.1.1) (1.7.1)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.7/dist-packages (from optimum[onnxruntime]==1.1.1) (1.11.0+cu113)\n",
            "Collecting coloredlogs\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[K     |████████████████████████████████| 46 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting datasets>=1.2.1\n",
            "  Downloading datasets-2.1.0-py3-none-any.whl (325 kB)\n",
            "\u001b[K     |████████████████████████████████| 325 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting onnxruntime\n",
            "  Downloading onnxruntime-1.11.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.2 MB 35.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (0.70.12.2)\n",
            "Collecting responses<0.19\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (1.3.5)\n",
            "Collecting fsspec[http]>=2021.05.0\n",
            "  Downloading fsspec-2022.3.0-py3-none-any.whl (136 kB)\n",
            "\u001b[K     |████████████████████████████████| 136 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (0.3.4)\n",
            "Collecting aiohttp\n",
            "  Downloading aiohttp-3.8.1-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 31.1 MB/s \n",
            "\u001b[?25hCollecting xxhash\n",
            "  Downloading xxhash-3.0.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (212 kB)\n",
            "\u001b[K     |████████████████████████████████| 212 kB 44.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers==4.18.0) (3.0.8)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.12.2->onnx==1.11.0) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.18.0) (2021.10.8)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 43.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (2.0.12)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.7.2-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 40.5 MB/s \n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (21.4.0)\n",
            "Collecting asynctest==0.13.0\n",
            "  Downloading asynctest-0.13.0-py3-none-any.whl (26 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (144 kB)\n",
            "\u001b[K     |████████████████████████████████| 144 kB 47.4 MB/s \n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.2-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (94 kB)\n",
            "\u001b[K     |████████████████████████████████| 94 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.2.0-py3-none-any.whl (8.2 kB)\n",
            "Collecting humanfriendly>=9.1\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.18.0) (3.8.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets>=1.2.1->optimum[onnxruntime]==1.1.1) (2022.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.18.0) (1.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.7/dist-packages (from sympy->optimum[onnxruntime]==1.1.1) (1.2.1)\n",
            "Building wheels for collected packages: folium, optimum, sacremoses\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79808 sha256=dbc184fd8129b722599da4597f0f445535f71484a005d5e452314650031c57f8\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "  Building wheel for optimum (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for optimum: filename=optimum-1.1.1-py3-none-any.whl size=83821 sha256=1276ff39aeba82149e9679a1622db348d790291931060576579e07bfef312ef1\n",
            "  Stored in directory: /root/.cache/pip/wheels/15/fd/0e/f2d8b5936fd9a3b231b0146ad0233d0572879e5a22378c9a16\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895260 sha256=43fe9811d9fc5fe8fe65e4011df6d5240a513b299b723445471248b4cb18b6dd\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/39/dd/a83eeef36d0bf98e7a4d1933a4ad2d660295a40613079bafc9\n",
            "Successfully built folium optimum sacremoses\n",
            "Installing collected packages: urllib3, multidict, frozenlist, yarl, pyyaml, asynctest, async-timeout, aiosignal, tokenizers, sacremoses, humanfriendly, huggingface-hub, fsspec, aiohttp, xxhash, transformers, responses, coloredlogs, optimum, onnxruntime, onnx, datasets, onnxruntime-gpu, folium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed aiohttp-3.8.1 aiosignal-1.2.0 async-timeout-4.0.2 asynctest-0.13.0 coloredlogs-15.0.1 datasets-2.1.0 folium-0.2.1 frozenlist-1.3.0 fsspec-2022.3.0 huggingface-hub-0.5.1 humanfriendly-10.0 multidict-6.0.2 onnx-1.11.0 onnxruntime-1.11.1 onnxruntime-gpu-1.11.0 optimum-1.1.1 pyyaml-6.0 responses-0.18.0 sacremoses-0.0.53 tokenizers-0.12.1 transformers-4.18.0 urllib3-1.25.11 xxhash-3.0.0 yarl-1.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install onnx==1.11.0 transformers==4.18.0 onnxruntime-gpu==1.11.0 folium==0.2.1 optimum[onnxruntime]==1.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2LrH-YLj6jK"
      },
      "source": [
        "Фиксируем версии библиотек, чтобы не потерялось"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "RJtoXVKbj43r"
      },
      "outputs": [],
      "source": [
        "!pip freeze > req_ways_of_convert_rubert_sentiment_classification.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yX3P6Agw6jsm"
      },
      "source": [
        "Импорты"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "UPvsKtuB6iyY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn.utils import prune\n",
        "from torch.onnx import TrainingMode\n",
        "from transformers import AutoModelForSequenceClassification, BertTokenizerFast, AutoConfig\n",
        "from transformers.onnx import export, OnnxConfig\n",
        "import onnxruntime as nxrun\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "import onnx\n",
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "import pandas as pd\n",
        "from optimum.onnxruntime import ORTQuantizer\n",
        "from optimum.onnxruntime.configuration import AutoQuantizationConfig\n",
        "from typing import OrderedDict\n",
        "from pathlib import Path"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качаем датасет, на котором будем проверять качество модели. Это часть датасета [RuReviews](https://github.com/sismetanin/rureviews/raw/master/women-clothing-accessories.3-class.balanced.csv) в размере 1к строк. Для удобства метки класса заменены на цифровые значения в соответсвии с метками класса модели rubert-base-cased-sentiment"
      ],
      "metadata": {
        "id": "PeVa2PBwZ-63"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/starminalush/mlops_report/raw/main/validation.csv"
      ],
      "metadata": {
        "id": "bswJJzJwZ-ZP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdcef9ae-7108-4f50-8c98-fd075ae850d5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-05-06 20:28:02--  https://github.com/starminalush/mlops_report/raw/main/validation.csv\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/starminalush/mlops_report/main/validation.csv [following]\n",
            "--2022-05-06 20:28:03--  https://raw.githubusercontent.com/starminalush/mlops_report/main/validation.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 238275 (233K) [text/plain]\n",
            "Saving to: ‘validation.csv’\n",
            "\n",
            "validation.csv      100%[===================>] 232.69K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-05-06 20:28:03 (8.92 MB/s) - ‘validation.csv’ saved [238275/238275]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Об нейросети"
      ],
      "metadata": {
        "id": "bN3PMwCwKu8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В качестве подопытного будем использовать [rubert-base-cased-sentiment](https://huggingface.co/blanchefort/rubert-base-cased-sentiment) для классификации русских предложений. Данная нейросеть предсказывает 3 метки класса, в зависимости от тона предложения - позитивное, негативное или нейтральное"
      ],
      "metadata": {
        "id": "OnWsmqJ8JEID"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCV1_Y3hjr4C"
      },
      "source": [
        "Запускаем нейросеть как есть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "y68sxMotjS-K",
        "outputId": "38facd66-c9ad-4387-c0b5-9e073ffb2407",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "de4814b5ff6741038a93092400a12700",
            "f6b6f36b132a4116a6f0a2ccb3948b3a",
            "a0d6c5a8679b47ecb8eac6eb42b7ec25",
            "6c4ad843af634b419b12b5357599669d",
            "c6237b87196d45ac90151faf110a2eeb",
            "e1dcec1fa3184769b303e5398939f32e",
            "dd5dc3470ffe4d77bcee451e29f44d0b",
            "6d56d52e20dc4e029bbd2f32454186af",
            "38693f106487429b81f3361a648b4953",
            "e1311ec9e8794db0877d58917ddeb5a9",
            "70fc404b49de46b19e623df0461718db",
            "41954feb42d94f988fa8a73c58c26447",
            "46b7b834c75e4e989eae77c637de33b1",
            "8fd7248b7b8043999aad886de77f4359",
            "eb9c4189f87f490aa34846c97a8e864b",
            "f96443f7f69d40c29890f670842d35de",
            "e26cc604e57a4ff49895f02aaa8df03e",
            "85460c3f9fc542fc90fff5207b056daf",
            "9c8927de1cdc409d884338123824c5d8",
            "61a2aac9dceb494f81bd3ab81fa31f2a",
            "a6eece113bf44ccd871e580b2176ff97",
            "5f889b962fd441aebecf96f448075478",
            "c1ed7d79af684e13940391e12fd77544",
            "5e097debbe0c42d28bda81f93fe55875",
            "0a68c7a01c2447a8ae4edcbc688338ac",
            "481de226275d4697b4334c3283287a52",
            "b7623fd82fb848a2b2e7e3e10bffe4c7",
            "eaf56296dcf244259078057f1095b1dd",
            "fa5c5554b3674be08e13f779b311eacb",
            "e3257188332e4d45ac17842899d21ded",
            "3c9119035bff4efe8e91fbc36a79217d",
            "2fb9665fe61f42f49079b60715ffa383",
            "ffd5a7c1155945028bb50dda179ffa2d",
            "83db2516631f428bbee6a7c8e8323e99",
            "c2b945e1f7c94e4c8d2a99bff030fe9f",
            "98f34b870a1d435ba0da5c994c39c75f",
            "2ce2cd7731244900a99d69f501ec5a05",
            "cddcf50684f1411687fa08755b07787c",
            "1b2218f694ca49e5ac0e7c9391bf4b28",
            "fc65f5c8add0461281553e8252b339fc",
            "60a02273336c4c7fb663e01249f183f6",
            "8cd30ba5471b4ab69338a2c74eda49a3",
            "1496dce707fb4d39a7fe70a9a5a4f549",
            "f5db0f814fd04218876830a1c3758d1e",
            "af51a9f698b24b7284a85857b7cb1f3e",
            "1e96a5fafac84466bdf1d5852da3d8bf",
            "2d44242b48944ab893e84777e067b157",
            "d64c2f1be8a04ee3bfa7d3da22a53e3e",
            "9e14259c99e14b53a197d0a4dfd092db",
            "84e0445963174d10a82f97f02daa83fd",
            "332d39ed8cc44a73bfa329efb63ebd72",
            "87089e45fd6a42cbb815dd855ef373d5",
            "2a204ec3632b4c6896a426adacb35115",
            "d86724ad066f4bfeaaeb9de2cb3df0fb",
            "2574e3d248a5482fa293c7137d4a0705"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/499 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de4814b5ff6741038a93092400a12700"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.34M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41954feb42d94f988fa8a73c58c26447"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ed7d79af684e13940391e12fd77544"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/943 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83db2516631f428bbee6a7c8e8323e99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/679M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "af51a9f698b24b7284a85857b7cb1f3e"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment')\n",
        "model = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True)\n",
        "\n",
        "@torch.no_grad()\n",
        "def predict(text, device):\n",
        "    model_local = model.to(device)\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = model_local(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Как задолбали эти тупые правила: не есть кота, не бить посуду, не есть кота'"
      ],
      "metadata": {
        "id": "j3WKSWz8bsoJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проверим время инференса модели на gpu и cpu"
      ],
      "metadata": {
        "id": "tj7kkrS1R2KL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "halOX7lokqyT",
        "outputId": "ce2a35b5-7fa2-4076-a053-b7e20e1e4e5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 104 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict(text, device = torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "predict(text, device = torch.device('cuda'))"
      ],
      "metadata": {
        "id": "VbLhAo36BRtO",
        "outputId": "2c009094-a9c2-4f6f-d6a5-09b4d15e40df",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 502.69 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 22.4 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузим валидациооный датасет и посчитаем на нем качество модели"
      ],
      "metadata": {
        "id": "uiIVxOFdB4mQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('validation.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "Blvw3zQqVSZS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "518bda37-d0d9-4dbc-cd25-43e02d9002a8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  Очень хорошая куртка, довольно таки плотная. Я...          1\n",
              "1  Заказ так и не пришёл, деньги не вернули. Спор...          2\n",
              "2                                             Пришло          0\n",
              "3  Заказывала S. Размер подошёл. Но есть одно но,...          0\n",
              "4  на спине между лямками дырка. продавец ничего ...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9382a322-008e-4a43-801e-7d3a9d00314e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Очень хорошая куртка, довольно таки плотная. Я...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Заказ так и не пришёл, деньги не вернули. Спор...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Пришло</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Заказывала S. Размер подошёл. Но есть одно но,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>на спине между лямками дырка. продавец ничего ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9382a322-008e-4a43-801e-7d3a9d00314e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9382a322-008e-4a43-801e-7d3a9d00314e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9382a322-008e-4a43-801e-7d3a9d00314e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для удобства выгрузим сэмплы и метки класса для них в отдельные списки"
      ],
      "metadata": {
        "id": "QwNFigwRX451"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texts = list(df['review'])\n",
        "labels = list(df['sentiment'])"
      ],
      "metadata": {
        "id": "sziEW5X3X8qD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict(text=t, device=torch.device('cuda')) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZg4zSOAYSAk",
        "outputId": "72ea2b76-6430-49e1-f16c-fd50ee111d6c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7570952595655819, recall: 0.7528932881996591, f1score: 0.7418477839235202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохраним оригинальную модель и посмотрим на ее вес"
      ],
      "metadata": {
        "id": "YCTWXOk829Pe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output"
      ],
      "metadata": {
        "id": "uNKv-i2QcfGP"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model, 'output/original.pt')"
      ],
      "metadata": {
        "id": "mtpd-cj53F_V"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/original.pt"
      ],
      "metadata": {
        "id": "Jy4Ok3jw3OUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1588085-a7ea-4d74-8db2-e035b3cb200f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/original.pt\n",
            "679M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ONNX"
      ],
      "metadata": {
        "id": "ITuXOm0CZ0Pc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формат Open Neural Network Exchange (ONNX) обеспечит общий способ представления данных, используемых в нейронных сетях. Большинство платформ имеют сегодня собственный специфический формат моделей, которые способны работать с моделями других платформ только при использовании специальных инструментов преобразования форматов.\n",
        "\n",
        "ONNX позволит осуществлять свободный обмен информацией, которой обладают модели, без процедуры преобразования. Модель, обученную на одной платформе, можно будет использовать и на другой платформе. Также можно будет модель, обученную на одном фреймворке, перенести на другой фреймворк.\n",
        "\n",
        "Перевести модель в ONNX можно несколькими способами:"
      ],
      "metadata": {
        "id": "p0aL7IAQaHje"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Есть способ конвертации модели через torch.onnx"
      ],
      "metadata": {
        "id": "goPzxMVnadSP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "S6uO6quNkUSn"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/onnx_transforms"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#делаем dummy input\n",
        "dummy_input0 = torch.randint(1, 224, (1,512))\n",
        "dummy_input1 = torch.randint(0, 1, (1,512 ))\n",
        "dummy_input2 =  torch.randint(0, 1, (1,512 ))\n",
        "dummy_inputs = (dummy_input0,dummy_input1,dummy_input2)\n",
        "device = torch.device('cpu')\n",
        "with torch.no_grad():\n",
        "  symbolic_names = {0:'batch_size', 1: 'max_seq_len'} \n",
        "  torch.onnx.export(model.to(device),               # модель, которую будем экспортировать\n",
        "                    dummy_inputs,                         # input модели\n",
        "                    \"output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\",   # путь сохранения модель\n",
        "                    export_params=True,        \n",
        "                    opset_version=11,          # версия ONNX, в который будем экспортировать модель\n",
        "                    do_constant_folding=True,\n",
        "                    input_names = [\"input_ids\",\"attention_mask\",\"token_type_ids\"],\n",
        "                    output_names = ['output'],\n",
        "                    dynamic_axes={'input_ids': symbolic_names,        #если у нас динамический размер input\n",
        "                                  'attention_mask' : symbolic_names,\n",
        "                                  'token_type_ids' : symbolic_names},\n",
        "                    training=TrainingMode.EVAL\n",
        "                    )"
      ],
      "metadata": {
        "id": "AsPlz8DGauZV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMKViWTow1s_"
      },
      "source": [
        "Пробуем запустить в ONNX на gpu и cpu и посмотреть время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "CeVlwXC8xbpj"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "# запуск на gpu\n",
        "providers = [\n",
        "    'CUDAExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iAu2HFt6x9WM"
      },
      "outputs": [],
      "source": [
        "def predict_onnx(text):\n",
        "  inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='np')\n",
        "  outputs  = model_ONNX.run(None, dict(inputs))[0][0]\n",
        "  result = np.where(outputs == np.amax(outputs))[0][0]\n",
        "  return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "d76ecT6N0a9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163d5f63-d288-4b44-c9ce-65c0b7226190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 4.52 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "100 loops, best of 5: 11.8 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit \n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#запуск на cpu\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\", sess_options, providers)"
      ],
      "metadata": {
        "id": "ZYY5rWVhCCoV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit \n",
        "predict_onnx(text)"
      ],
      "metadata": {
        "id": "maNwRh-MCIym",
        "outputId": "c3438229-fbcf-4429-9d75-b772eec9a12b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 78.9 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "rdcziw6HeR6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(text = t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "_t96PNPob8I0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdd9a58c-be05-40da-acaf-e8eb172652f2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7570952595655819, recall: 0.7528932881996591, f1score: 0.7418477839235202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "UrZPxeh_jCk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/onnx_transforms/*"
      ],
      "metadata": {
        "id": "BXjx9u88jFDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a171555e-18d2-4a57-ebfa-7f5944e80ef0"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/onnx_transforms/rubert-base-cased-sentiment_torch.onnx\n",
            "679M\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала на порядок выше, метрики качества не изменились"
      ],
      "metadata": {
        "id": "ncawUB5neW9b"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhA84H-tlJCl"
      },
      "source": [
        "2. Есть библиотека transforms для трансформеров, [где все почти из коробки](https://huggingface.co/docs/transformers/serialization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dXO_0DXu3e3s"
      },
      "outputs": [],
      "source": [
        "class DistilBertOnnxConfig(OnnxConfig):\n",
        "    @property\n",
        "    def inputs(self):\n",
        "        return OrderedDict(\n",
        "            [\n",
        "                (\"input_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"attention_mask\", {0: \"batch\", 1: \"sequence\"}),\n",
        "                (\"token_type_ids\", {0: \"batch\", 1: \"sequence\"}),\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "kFThnLqO3O6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "368d98a8-a42d-4df8-ec38-7a73bdd3a725"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "OrderedDict([('logits', {0: 'batch'})])\n"
          ]
        }
      ],
      "source": [
        "config = AutoConfig.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\")\n",
        "onnx_config_for_seq_clf = DistilBertOnnxConfig(config, task=\"sequence-classification\")\n",
        "print(onnx_config_for_seq_clf.outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8hPCv74Ylcje"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cpu')\n",
        "onnx_inputs, onnx_outputs = export(\n",
        "        tokenizer,\n",
        "        model.to(device),\n",
        "        onnx_config_for_seq_clf,\n",
        "        output=Path(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\"),\n",
        "        opset=11)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если проверить скорость инференса и качество, получим то же самое, так что проверим только на gpu"
      ],
      "metadata": {
        "id": "WhrVYCm5w96r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "IvtrvbmqxCT7"
      },
      "outputs": [],
      "source": [
        "providers = [\n",
        "    'CUDAExecutionProvider'\n",
        "]\n",
        "model_ONNX = nxrun.InferenceSession(\"output/onnx_transforms/rubert-base-cased-sentiment.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a81d1e70-1a9a-4b2f-b553-eb20f31d6250",
        "id": "REK315RPxCT8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 11.8 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b642c8a5-8b95-4d42-cbd7-bf26ef2f937b",
        "id": "Y-7g0KH1xLXL"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7570952595655819, recall: 0.7528932881996591, f1score: 0.7418477839235202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TorchScript"
      ],
      "metadata": {
        "id": "6QZEJMl0exff"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TorchScript — инструмент, который позволяет с помощью пары строк кода и нескольких щелчков мыши сделать из пайплайна на питоне отчуждаемое решение, которое можно встроить в систему на C++. А еще она будет на python работать быстрее из-за jit компиляции. В библиотеке transformers так же [есть почти из коробки](https://huggingface.co/docs/transformers/serialization#torchscript)"
      ],
      "metadata": {
        "id": "OOFNgikneVzn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "z_Gx7ViOnovm"
      },
      "outputs": [],
      "source": [
        "tokenizer_torchscript = BertTokenizerFast.from_pretrained('blanchefort/rubert-base-cased-sentiment', torchscript = True)\n",
        "model_torchscript = AutoModelForSequenceClassification.from_pretrained('blanchefort/rubert-base-cased-sentiment', return_dict=True, torchscript=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "tSjgRCg-nbhs"
      },
      "outputs": [],
      "source": [
        "dummy_input0 = torch.randint(1, 224, (1,512))\n",
        "dummy_input1 = torch.randint(0, 1, (1,512 ))\n",
        "dummy_input2 =  torch.randint(0, 1, (1,512 ))\n",
        "traced_model = torch.jit.trace(model_torchscript, [x.clone().detach() for x in dummy_inputs])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "rN15KXu3s_ZX"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/torchscript"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.jit.save(traced_model, \"output/torchscript/rubert-base-cased-sentiment_traced.pt\")"
      ],
      "metadata": {
        "id": "fWRFFZt1gMPP"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMMMa85wtFU5"
      },
      "source": [
        "Пробуем загрузить и предиктить на gpu и cpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "traced_model = torch.jit.load(\"output/torchscript/rubert-base-cased-sentiment_traced.pt\")"
      ],
      "metadata": {
        "id": "h7HUSg2wy2AE"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gkJz0sciq9K5"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_torchscript(text, device):\n",
        "    local_model = traced_model.to(device)\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = local_model(**inputs)[0]\n",
        "    predicted = torch.nn.functional.softmax(outputs, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "bXfsa0HOtY-c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81c22aa8-1145-493a-e030-1ebf22b4983c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 9.93 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 205 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict_torchscript(text = text, device = torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "predict_torchscript(text = text, device = torch.device('cuda'))"
      ],
      "metadata": {
        "id": "yzRS_gFWC61j",
        "outputId": "558bb037-a6e4-4b12-de65-af29b9f760d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 352.32 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 24.2 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество модели"
      ],
      "metadata": {
        "id": "-wlPWFDfghd9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_torchscript(text=t, device = torch.device('cuda')) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "FW3k65H6gj7p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e617f7c3-2bf8-4967-8db1-c6ccc94c0a2c"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7570952595655819, recall: 0.7528932881996591, f1score: 0.7418477839235202\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "xBMIZs9_i907"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "WRTog6pvuSL1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "198bec50-7ffb-4390-e6c9-e22ce1e18db9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/torchscript/rubert-base-cased-sentiment_traced.pt\n",
            "679M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/torchscript/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод:  по сравнению с оригинальной моделью скорость инференса модели стала немного выше, метрики качества не изменились. Лучше, чем ничего. Нужно на с++ запускать, чтобы увидеть результат сильно лучше "
      ],
      "metadata": {
        "id": "glxV-dR4jfW8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Прунинг модели"
      ],
      "metadata": {
        "id": "7jV0b67TjnwZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model Pruning — обрезание избыточных частей сети для ускорения инференса без потери точности. Наглядно — откуда, сколько и как можно вырезать."
      ],
      "metadata": {
        "id": "KslsGyjYkFes"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть очень много способов прунинга моделей, но здесь мы рассмотрим способ прунинга attention слоев"
      ],
      "metadata": {
        "id": "0PyJxe0RaJ4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Есть два варианта, как прунить модель.\n",
        "\n",
        "1 вариант - делать через torch.nn.utils.prune. В качестве примера есть данный [ноутбук](https://github.com/Huffon/nlp-various-tutorials/blob/master/pruning-bert.ipynb)\n",
        "\n",
        "2 вариант - библиотека [nn_pruning](https://github.com/huggingface/nn_pruning) от HuggingFace\n"
      ],
      "metadata": {
        "id": "QQecIsnQx431"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpTwYCLrvtsi"
      },
      "source": [
        "[Ссылка](https://aclanthology.org/2020.repl4nlp-1.18.pdf) на почитать про прунинг модели BERT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMxrxaTf9yCy"
      },
      "source": [
        "Посмотрим на саму модель. Видим, что большую ее часть занимают attention слои. Давайте их и запруним и посмотрим, что получится"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "laqVNM52oYsS",
        "outputId": "836a0302-910f-4430-aa05-5c55d6d2399a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertForSequenceClassification(\n",
            "  (bert): BertModel(\n",
            "    (embeddings): BertEmbeddings(\n",
            "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
            "      (position_embeddings): Embedding(512, 768)\n",
            "      (token_type_embeddings): Embedding(2, 768)\n",
            "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (encoder): BertEncoder(\n",
            "      (layer): ModuleList(\n",
            "        (0): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (1): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (2): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (3): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (4): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (5): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (6): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (7): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (8): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (9): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (10): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (11): BertLayer(\n",
            "          (attention): BertAttention(\n",
            "            (self): BertSelfAttention(\n",
            "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "            (output): BertSelfOutput(\n",
            "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (intermediate): BertIntermediate(\n",
            "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (intermediate_act_fn): GELUActivation()\n",
            "          )\n",
            "          (output): BertOutput(\n",
            "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): BertPooler(\n",
            "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (activation): Tanh()\n",
            "    )\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "aunSquBo4Qr9"
      },
      "outputs": [],
      "source": [
        "pruned_model = model\n",
        "\n",
        "parameters_to_prune = ()\n",
        "for i in range(12):\n",
        "    parameters_to_prune += (\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.key, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.query, 'weight'),\n",
        "        (pruned_model.bert.encoder.layer[i].attention.self.value, 'weight'),\n",
        "    )\n",
        "\n",
        "prune.global_unstructured(\n",
        "    parameters_to_prune,\n",
        "    pruning_method=prune.L1Unstructured,\n",
        "    amount=0.8\n",
        ")\n",
        "for p in parameters_to_prune:\n",
        "  prune.remove(p[0], 'weight')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Выведем, что получилось"
      ],
      "metadata": {
        "id": "AVBZ5em9y7y7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "brkL0Q0u72EK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f313aac0-b0b3-4017-cfd3-fcd171ac0666"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sparsity in Layer 1-th key weight: 77.23%\n",
            "Sparsity in Layer 1-th query weightt: 77.17%\n",
            "Sparsity in Layer 1-th value weight: 91.60%\n",
            "\n",
            "Sparsity in Layer 2-th key weight: 77.46%\n",
            "Sparsity in Layer 2-th query weightt: 76.82%\n",
            "Sparsity in Layer 2-th value weight: 90.37%\n",
            "\n",
            "Sparsity in Layer 3-th key weight: 80.21%\n",
            "Sparsity in Layer 3-th query weightt: 79.54%\n",
            "Sparsity in Layer 3-th value weight: 87.01%\n",
            "\n",
            "Sparsity in Layer 4-th key weight: 77.59%\n",
            "Sparsity in Layer 4-th query weightt: 77.35%\n",
            "Sparsity in Layer 4-th value weight: 88.18%\n",
            "\n",
            "Sparsity in Layer 5-th key weight: 76.99%\n",
            "Sparsity in Layer 5-th query weightt: 76.74%\n",
            "Sparsity in Layer 5-th value weight: 85.86%\n",
            "\n",
            "Sparsity in Layer 6-th key weight: 76.24%\n",
            "Sparsity in Layer 6-th query weightt: 75.17%\n",
            "Sparsity in Layer 6-th value weight: 82.86%\n",
            "\n",
            "Sparsity in Layer 7-th key weight: 77.00%\n",
            "Sparsity in Layer 7-th query weightt: 75.85%\n",
            "Sparsity in Layer 7-th value weight: 83.59%\n",
            "\n",
            "Sparsity in Layer 8-th key weight: 77.44%\n",
            "Sparsity in Layer 8-th query weightt: 76.97%\n",
            "Sparsity in Layer 8-th value weight: 81.95%\n",
            "\n",
            "Sparsity in Layer 9-th key weight: 76.54%\n",
            "Sparsity in Layer 9-th query weightt: 76.23%\n",
            "Sparsity in Layer 9-th value weight: 84.85%\n",
            "\n",
            "Sparsity in Layer 10-th key weight: 77.35%\n",
            "Sparsity in Layer 10-th query weightt: 76.76%\n",
            "Sparsity in Layer 10-th value weight: 83.97%\n",
            "\n",
            "Sparsity in Layer 11-th key weight: 77.69%\n",
            "Sparsity in Layer 11-th query weightt: 77.06%\n",
            "Sparsity in Layer 11-th value weight: 85.45%\n",
            "\n",
            "Sparsity in Layer 12-th key weight: 77.73%\n",
            "Sparsity in Layer 12-th query weightt: 77.04%\n",
            "Sparsity in Layer 12-th value weight: 82.12%\n",
            "\n",
            "Global sparsity: 80.00%\n"
          ]
        }
      ],
      "source": [
        "for i in range(12):\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th key weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th query weightt: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print(\n",
        "        \"Sparsity in Layer {}-th value weight: {:.2f}%\".format(\n",
        "            i+1,\n",
        "            100. * float(torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0))\n",
        "            / float(pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement())\n",
        "        )\n",
        "    )\n",
        "    print()\n",
        "\n",
        "    \n",
        "numerator, denominator = 0, 0\n",
        "for i in range(12):\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.key.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.query.weight == 0)\n",
        "    numerator += torch.sum(pruned_model.bert.encoder.layer[i].attention.self.value.weight == 0)\n",
        "\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.key.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.query.weight.nelement()\n",
        "    denominator += pruned_model.bert.encoder.layer[i].attention.self.value.weight.nelement()\n",
        "    \n",
        "print(\"Global sparsity: {:.2f}%\".format(100. * float(numerator) / float(denominator)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0L0XqK9i9Wqx"
      },
      "source": [
        "Предиктим на запруненной модели на gpu и cpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "5DX9s0-a9VW7"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def predict_pruned(text, device):\n",
        "    local_model = pruned_model.to(device)\n",
        "    inputs = tokenizer(text, max_length=512, padding=True, truncation=True, return_tensors='pt').to(device)\n",
        "    outputs = local_model(**inputs)\n",
        "    predicted = torch.nn.functional.softmax(outputs.logits, dim=1)\n",
        "    predicted = torch.argmax(predicted, dim=1).cpu().numpy()\n",
        "    return predicted[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "oKkXd1Yc9jtA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf15184-8ae8-427b-cf7b-313323a30a0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 104 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict_pruned(text, device = torch.device('cpu'))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "predict_pruned(text, device = torch.device('cuda'))"
      ],
      "metadata": {
        "id": "keJst4-ADc6D",
        "outputId": "754d03d4-0c50-49e3-80b6-2a3955fc0548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 13.06 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 5: 16 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "tmheSjAr9rt2"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "S6-5H9Cq-k9m"
      },
      "outputs": [],
      "source": [
        "torch.save(pruned_model, 'output/pruning/rubert-base-cased-sentiment_pruned.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем качество модели"
      ],
      "metadata": {
        "id": "jk8IWvdqzaiD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_pruned(text = t, device=torch.device('cuda')) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "tiTTVRFBzqOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "613e62de-1554-425a-e8be-ee076042d095"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7857382454161307, recall: 0.7640992817069839, f1score: 0.7684815271783668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Посмотрим на вес модели"
      ],
      "metadata": {
        "id": "N1voUhql0oZ2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "DzLIjxUd0oZ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b70be5-f2bd-49e7-8a40-254e58eb1613"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "679M\toutput/pruning/rubert-base-cased-sentiment_pruned.pt\n",
            "679M\ttotal\n"
          ]
        }
      ],
      "source": [
        "!du -shc output/pruning/*"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод - вес модели не поменялся, качество даже чуть-чуть улучшилось по сравнению с оригинальной моделью, но не критично"
      ],
      "metadata": {
        "id": "5r9o1Bhk04UB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Квантизация"
      ],
      "metadata": {
        "id": "ygi6u3xv3nK_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDQnTXSifdnm"
      },
      "source": [
        "Квантизация означает уменьшение численной точности весов модели. Один из популярных методов — k-means квантизация. Имея веса модели в матрице W с десятичными числами, веса кластеризуются с помощью k-means в N кластеров. Затем матрица W трансформируется в матрицу целых чисел от 1 до N, каждое из которых является указателем к центру кластера. Так можно сжать каждый элемент изначальной матрицы из 32-битного десятичного числа в log(N)-битные целые числа.\n",
        "\n",
        "Есть три вида квантизации - статическая, динамическая и Quantization-Aware-Training(QAT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd3MXWSQf1bF"
      },
      "source": [
        "Динамическая квантизация не требует ничего, поэтому она самая простая"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "SIteomPhgK3j"
      },
      "outputs": [],
      "source": [
        "!mkdir -p output/quantization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно квантизировать модель через библиотеку onnxruntime \n",
        "(!Внимание, операция очень тяжелая, вам может не хватить памяти в колабе, лучше запускать отдельно. Так же onnxruntime не работает с квантизированными моделями на gpu, потому запустится она только на cpu)"
      ],
      "metadata": {
        "id": "zP9ACDI5yVLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_fp32 = 'output/onnx_transforms/rubert-base-cased-sentiment_torch.onnx'\n",
        "model_quant = 'output/quantization/rubert-base-cased-sentiment.quant.onnx'\n",
        "quantized_model = quantize_dynamic(model_fp32, model_quant, weight_type=QuantType.QUInt8)"
      ],
      "metadata": {
        "id": "U3TcKmpmyaRv",
        "outputId": "7a8367e1-2af0-46bf-f669-ce89d9df33af",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignore MatMul due to non constant B: /[MatMul_68]\n",
            "Ignore MatMul due to non constant B: /[MatMul_73]\n",
            "Ignore MatMul due to non constant B: /[MatMul_162]\n",
            "Ignore MatMul due to non constant B: /[MatMul_167]\n",
            "Ignore MatMul due to non constant B: /[MatMul_256]\n",
            "Ignore MatMul due to non constant B: /[MatMul_261]\n",
            "Ignore MatMul due to non constant B: /[MatMul_350]\n",
            "Ignore MatMul due to non constant B: /[MatMul_355]\n",
            "Ignore MatMul due to non constant B: /[MatMul_444]\n",
            "Ignore MatMul due to non constant B: /[MatMul_449]\n",
            "Ignore MatMul due to non constant B: /[MatMul_538]\n",
            "Ignore MatMul due to non constant B: /[MatMul_543]\n",
            "Ignore MatMul due to non constant B: /[MatMul_632]\n",
            "Ignore MatMul due to non constant B: /[MatMul_637]\n",
            "Ignore MatMul due to non constant B: /[MatMul_726]\n",
            "Ignore MatMul due to non constant B: /[MatMul_731]\n",
            "Ignore MatMul due to non constant B: /[MatMul_820]\n",
            "Ignore MatMul due to non constant B: /[MatMul_825]\n",
            "Ignore MatMul due to non constant B: /[MatMul_914]\n",
            "Ignore MatMul due to non constant B: /[MatMul_919]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1008]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1013]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1102]\n",
            "Ignore MatMul due to non constant B: /[MatMul_1107]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--7npahjgBwa"
      },
      "source": [
        "Пробуем запустить динамечески квантизированную ONNX модель и посмотреть на время инференса"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "DcPhqkvdgPZv"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/quantization/rubert-base-cased-sentiment.quant.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ab-IIy12gSnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0337959-2756-4155-aa66-7e9d8b1755f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 56 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Считаем качество"
      ],
      "metadata": {
        "id": "EQ0Agafp43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "xuQ36XHV43uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1ef49d5-a81c-43ee-9505-1f39599fefaf"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7545168261175811, recall: 0.7505926047060564, f1score: 0.7370407334951347\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно так же через библиотеку optimum от transformers"
      ],
      "metadata": {
        "id": "YLil08WNY9Z2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "D5h7RVrMfUnP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "502af368-a29b-4af6-9fb2-0472e15af0ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx')"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ],
      "source": [
        "# The type of quantization to apply\n",
        "qconfig = AutoQuantizationConfig.arm64(is_static=False, per_channel=False)\n",
        "quantizer = ORTQuantizer.from_pretrained(\"blanchefort/rubert-base-cased-sentiment\", feature=\"sequence-classification\")\n",
        "\n",
        "# Quantize the model!\n",
        "quantizer.export(\n",
        "    onnx_model_path=\"output/quantization/rubert-base-cased-sentiment.onnx\",\n",
        "    onnx_quantized_model_output_path=\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\",\n",
        "    quantization_config=qconfig,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "iwadvXMQFIF_"
      },
      "outputs": [],
      "source": [
        "sess_options = nxrun.SessionOptions()\n",
        "providers = [\n",
        "    'CPUExecutionProvider'\n",
        "]\n",
        "\n",
        "model_ONNX = nxrun.InferenceSession(\"output/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\", sess_options, providers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "l5m3Mrp6FIGH",
        "outputId": "443957f1-18cf-4f10-bee7-27ccedd421ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 loops, best of 5: 54.2 ms per loop\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "predict_onnx(text)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = [predict_onnx(t) for t in texts]\n",
        "precision, recall, f1score = precision_recall_fscore_support(labels, predictions,average='macro')[:3]\n",
        "\n",
        "print(f'precision: {precision}, recall: {recall}, f1score: {f1score}')"
      ],
      "metadata": {
        "id": "L7FDMgrYFIGI",
        "outputId": "84a38a11-aa51-4819-bf77-345c4d2ad9c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision: 0.7484010270774976, recall: 0.7457284129656573, f1score: 0.7327319314740698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посмотрим на веса моделей"
      ],
      "metadata": {
        "id": "EhFEQrOw43uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!du -shc output/quantization/*"
      ],
      "metadata": {
        "id": "1BWVnSpI43uB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8688faa0-33eb-44fe-8ea0-f4325df8875a"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "436M\toutput/quantization/rubert-base-cased-sentiment_dyn_quantized.onnx\n",
            "679M\toutput/quantization/rubert-base-cased-sentiment.onnx\n",
            "171M\toutput/quantization/rubert-base-cased-sentiment.quant.onnx\n",
            "1.3G\ttotal\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вывод - квантизированные модели весят сильно меньше, чем оригинальная. Скорость инференса при этом уменьшается почти в 1,5 раза, если учитывать скорость работы на CPU"
      ],
      "metadata": {
        "id": "kaRd5OiWFT6x"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of ways of convert rubert_sentiment_classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "https://github.com/starminalush/mlops_report/blob/main/ways_of_convert_rubert_sentiment_classification.ipynb",
      "authorship_tag": "ABX9TyNIiFDag0yKwZ7+fPIEI3bU",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "de4814b5ff6741038a93092400a12700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6b6f36b132a4116a6f0a2ccb3948b3a",
              "IPY_MODEL_a0d6c5a8679b47ecb8eac6eb42b7ec25",
              "IPY_MODEL_6c4ad843af634b419b12b5357599669d"
            ],
            "layout": "IPY_MODEL_c6237b87196d45ac90151faf110a2eeb"
          }
        },
        "f6b6f36b132a4116a6f0a2ccb3948b3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1dcec1fa3184769b303e5398939f32e",
            "placeholder": "​",
            "style": "IPY_MODEL_dd5dc3470ffe4d77bcee451e29f44d0b",
            "value": "Downloading: 100%"
          }
        },
        "a0d6c5a8679b47ecb8eac6eb42b7ec25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d56d52e20dc4e029bbd2f32454186af",
            "max": 499,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38693f106487429b81f3361a648b4953",
            "value": 499
          }
        },
        "6c4ad843af634b419b12b5357599669d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1311ec9e8794db0877d58917ddeb5a9",
            "placeholder": "​",
            "style": "IPY_MODEL_70fc404b49de46b19e623df0461718db",
            "value": " 499/499 [00:00&lt;00:00, 4.57kB/s]"
          }
        },
        "c6237b87196d45ac90151faf110a2eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e1dcec1fa3184769b303e5398939f32e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5dc3470ffe4d77bcee451e29f44d0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d56d52e20dc4e029bbd2f32454186af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38693f106487429b81f3361a648b4953": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e1311ec9e8794db0877d58917ddeb5a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70fc404b49de46b19e623df0461718db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41954feb42d94f988fa8a73c58c26447": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46b7b834c75e4e989eae77c637de33b1",
              "IPY_MODEL_8fd7248b7b8043999aad886de77f4359",
              "IPY_MODEL_eb9c4189f87f490aa34846c97a8e864b"
            ],
            "layout": "IPY_MODEL_f96443f7f69d40c29890f670842d35de"
          }
        },
        "46b7b834c75e4e989eae77c637de33b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e26cc604e57a4ff49895f02aaa8df03e",
            "placeholder": "​",
            "style": "IPY_MODEL_85460c3f9fc542fc90fff5207b056daf",
            "value": "Downloading: 100%"
          }
        },
        "8fd7248b7b8043999aad886de77f4359": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c8927de1cdc409d884338123824c5d8",
            "max": 1404983,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_61a2aac9dceb494f81bd3ab81fa31f2a",
            "value": 1404983
          }
        },
        "eb9c4189f87f490aa34846c97a8e864b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6eece113bf44ccd871e580b2176ff97",
            "placeholder": "​",
            "style": "IPY_MODEL_5f889b962fd441aebecf96f448075478",
            "value": " 1.34M/1.34M [00:00&lt;00:00, 2.38MB/s]"
          }
        },
        "f96443f7f69d40c29890f670842d35de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e26cc604e57a4ff49895f02aaa8df03e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85460c3f9fc542fc90fff5207b056daf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c8927de1cdc409d884338123824c5d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a2aac9dceb494f81bd3ab81fa31f2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a6eece113bf44ccd871e580b2176ff97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f889b962fd441aebecf96f448075478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1ed7d79af684e13940391e12fd77544": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e097debbe0c42d28bda81f93fe55875",
              "IPY_MODEL_0a68c7a01c2447a8ae4edcbc688338ac",
              "IPY_MODEL_481de226275d4697b4334c3283287a52"
            ],
            "layout": "IPY_MODEL_b7623fd82fb848a2b2e7e3e10bffe4c7"
          }
        },
        "5e097debbe0c42d28bda81f93fe55875": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eaf56296dcf244259078057f1095b1dd",
            "placeholder": "​",
            "style": "IPY_MODEL_fa5c5554b3674be08e13f779b311eacb",
            "value": "Downloading: 100%"
          }
        },
        "0a68c7a01c2447a8ae4edcbc688338ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3257188332e4d45ac17842899d21ded",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c9119035bff4efe8e91fbc36a79217d",
            "value": 112
          }
        },
        "481de226275d4697b4334c3283287a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2fb9665fe61f42f49079b60715ffa383",
            "placeholder": "​",
            "style": "IPY_MODEL_ffd5a7c1155945028bb50dda179ffa2d",
            "value": " 112/112 [00:00&lt;00:00, 595B/s]"
          }
        },
        "b7623fd82fb848a2b2e7e3e10bffe4c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eaf56296dcf244259078057f1095b1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa5c5554b3674be08e13f779b311eacb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3257188332e4d45ac17842899d21ded": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c9119035bff4efe8e91fbc36a79217d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2fb9665fe61f42f49079b60715ffa383": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffd5a7c1155945028bb50dda179ffa2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "83db2516631f428bbee6a7c8e8323e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c2b945e1f7c94e4c8d2a99bff030fe9f",
              "IPY_MODEL_98f34b870a1d435ba0da5c994c39c75f",
              "IPY_MODEL_2ce2cd7731244900a99d69f501ec5a05"
            ],
            "layout": "IPY_MODEL_cddcf50684f1411687fa08755b07787c"
          }
        },
        "c2b945e1f7c94e4c8d2a99bff030fe9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1b2218f694ca49e5ac0e7c9391bf4b28",
            "placeholder": "​",
            "style": "IPY_MODEL_fc65f5c8add0461281553e8252b339fc",
            "value": "Downloading: 100%"
          }
        },
        "98f34b870a1d435ba0da5c994c39c75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60a02273336c4c7fb663e01249f183f6",
            "max": 943,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8cd30ba5471b4ab69338a2c74eda49a3",
            "value": 943
          }
        },
        "2ce2cd7731244900a99d69f501ec5a05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1496dce707fb4d39a7fe70a9a5a4f549",
            "placeholder": "​",
            "style": "IPY_MODEL_f5db0f814fd04218876830a1c3758d1e",
            "value": " 943/943 [00:00&lt;00:00, 10.1kB/s]"
          }
        },
        "cddcf50684f1411687fa08755b07787c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2218f694ca49e5ac0e7c9391bf4b28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc65f5c8add0461281553e8252b339fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60a02273336c4c7fb663e01249f183f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cd30ba5471b4ab69338a2c74eda49a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1496dce707fb4d39a7fe70a9a5a4f549": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5db0f814fd04218876830a1c3758d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af51a9f698b24b7284a85857b7cb1f3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e96a5fafac84466bdf1d5852da3d8bf",
              "IPY_MODEL_2d44242b48944ab893e84777e067b157",
              "IPY_MODEL_d64c2f1be8a04ee3bfa7d3da22a53e3e"
            ],
            "layout": "IPY_MODEL_9e14259c99e14b53a197d0a4dfd092db"
          }
        },
        "1e96a5fafac84466bdf1d5852da3d8bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e0445963174d10a82f97f02daa83fd",
            "placeholder": "​",
            "style": "IPY_MODEL_332d39ed8cc44a73bfa329efb63ebd72",
            "value": "Downloading: 100%"
          }
        },
        "2d44242b48944ab893e84777e067b157": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87089e45fd6a42cbb815dd855ef373d5",
            "max": 711509513,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a204ec3632b4c6896a426adacb35115",
            "value": 711509513
          }
        },
        "d64c2f1be8a04ee3bfa7d3da22a53e3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86724ad066f4bfeaaeb9de2cb3df0fb",
            "placeholder": "​",
            "style": "IPY_MODEL_2574e3d248a5482fa293c7137d4a0705",
            "value": " 679M/679M [00:29&lt;00:00, 37.0MB/s]"
          }
        },
        "9e14259c99e14b53a197d0a4dfd092db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e0445963174d10a82f97f02daa83fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "332d39ed8cc44a73bfa329efb63ebd72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "87089e45fd6a42cbb815dd855ef373d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a204ec3632b4c6896a426adacb35115": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d86724ad066f4bfeaaeb9de2cb3df0fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2574e3d248a5482fa293c7137d4a0705": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}